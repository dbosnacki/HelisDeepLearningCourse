{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "modelTrainTestProteinDomainsWithPairFrequency.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMJfoCQi2YMuCuFIVHOxKnJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dbosnacki/HelisDeepLearningCourse/blob/main/modelTrainTestProteinDomainsWithPairFrequency.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oGiut-5Yl5j",
        "outputId": "3e6eb2ee-01ae-47cf-c0e7-4cad0bcd5593",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import time\n",
        "import csv\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import tensorflow.keras.backend as K\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "def makeSignature(dseqs, ordered = False):\n",
        "    \"\"\" Produce the letter pair occourrence signature of the (amino acid) sequence\"\"\"\n",
        "    \n",
        "    aminoAcids = ['A', 'R', 'N', 'D', 'C', 'Q', 'E', 'G', 'H', 'I', 'L',\\\n",
        "                  'K', 'M', 'F', 'P', 'S', 'T', 'W', 'Y', 'V']\n",
        "    signature = []\n",
        "        \n",
        "    if ordered:\n",
        "        for aa1 in aminoAcids:\n",
        "            for aa2 in aminoAcids:\n",
        "                signature.append(dseqs.count(aa1+aa2))\n",
        "    else:\n",
        "        for i in range(len(aminoAcids)):\n",
        "            for j in range(i+1):\n",
        "                if not (i == j): \n",
        "                    signature.append(dseqs.count(aminoAcids[i]+aminoAcids[j]) + dseqs.count(aminoAcids[j]+aminoAcids[i]))\n",
        "                else:\n",
        "                    signature.append(dseqs.count(aminoAcids[i]+aminoAcids[j]))\n",
        "    signature = np.array(signature)       \n",
        "    return signature\n",
        "\n",
        "#Loading, padding and one-hot encoding of the data\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/dbosnacki/HelisDeepLearningCourse/main/cath-domain-description-file-v2_4ProcessedForNN.tsv' \n",
        "df = pd.read_csv(url, delimiter = \"\\t\", header=None)\n",
        "\n",
        "# generate the signature (features) of the sequences based on pair frequencies\n",
        "sequences = list(df[3])\n",
        "\n",
        "dataset = []          \n",
        "        \n",
        "for sequence in sequences:\n",
        "    dataset.append(makeSignature(sequence))\n",
        "\n",
        "#labels = pd.DataFrame(df).to_numpy()\n",
        "labels = list(df[2])    \n",
        "   \n",
        "X = np.array(dataset)\n",
        "y = np.array(labels)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "accuracy_per_fold = []\n",
        "loss_per_fold = []\n",
        "\n",
        "#save_dir = '\\saved_models\\\\' \n",
        "fold_no = 1\n",
        "seed = 10\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
        "\n",
        "for train_index, val_index in skf.split(X_train, y_train):\n",
        "    \n",
        "    print('Fold: ' + str(fold_no))\n",
        "    \n",
        "\n",
        "    # Define Sequential model with 3 layers\n",
        "    model = keras.Sequential(\n",
        "        [\n",
        "           layers.Dense(128, input_shape = (len(X_train[0]), ), activation=\"relu\", name=\"layer1\"),\n",
        "           layers.Dense(64, activation=\"relu\", name=\"layer2\"),\n",
        "           layers.Dense(3, activation=\"sigmoid\", name=\"layer3\"),\n",
        "           #\n",
        "           # layers.Dense(1024, input_shape = (len(X_train[0]), ), activation=\"relu\", name=\"layer1\"),\n",
        "           # layers.Dense(256, activation=\"relu\", name=\"layer2\"),\n",
        "           # layers.Dense(64, activation=\"relu\", name=\"layer3\"),\n",
        "           # layers.Dense(4, activation=\"relu\", name=\"layer4\"),\n",
        "           # layers.Dense(3, activation=\"sigmoid\", name=\"layer5\"),\n",
        "           #\n",
        "           #layers.Dense(128, input_shape = (len(X_train[0]), ), activation=\"relu\", name=\"layer1\"),\n",
        "           #layers.Dense(64, activation=\"relu\", name=\"layer2\"),\n",
        "           #layers.Dense(32, activation=\"relu\", name=\"layer3\"),\n",
        "           #layers.Dense(16, activation=\"relu\", name=\"layer4\"),\n",
        "           #layers.Dense(8, activation=\"relu\", name=\"layer5\"),\n",
        "           #layers.Dense(3, activation=\"relu\", name=\"layer6\"),\n",
        "           #\n",
        "           #layers.Dense((32), input_shape = (len(X_train[0]), ), activation=\"relu\", name=\"layer1\"),\n",
        "           #layers.Dense(16, activation=\"relu\", name=\"layer2\"),\n",
        "           #layers.Dense(3, activation=\"sigmoid\", name=\"layer3\"),\n",
        "        ]\n",
        "    )\n",
        "    \n",
        "    # model.summary()\n",
        "\n",
        "    model.compile(\n",
        "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "        metrics=['accuracy'],\n",
        "        optimizer='adam',\n",
        "    )\n",
        "\n",
        "    history = model.fit(X_train[train_index], \n",
        "                        y_train[train_index], \n",
        "                        batch_size = 1024, \n",
        "                        epochs = 25, \n",
        "                        #class_weight = class_weight, \n",
        "                        validation_data = (X_train[val_index], y_train[val_index]),\n",
        "                        #callbacks = callbacks_list,\n",
        "                        verbose = 2)\n",
        "    \n",
        "    scores = model.evaluate(X_test, y_test, verbose=2)\n",
        "\n",
        "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "    accuracy_per_fold.append(scores[1] * 100)\n",
        "    loss_per_fold.append(scores[0])\n",
        "\n",
        "    # Increase fold number\n",
        "    fold_no = fold_no + 1\n",
        "\n",
        "# Average scores\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(len(accuracy_per_fold)):\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {accuracy_per_fold[i]}%')\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Average scores for all folds:')\n",
        "print(f'> Accuracy: {np.mean(accuracy_per_fold)} (+- {np.std(accuracy_per_fold)})')\n",
        "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "print('------------------------------------------------------------------------')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold: 1\n",
            "Epoch 1/25\n",
            "60/60 - 1s - loss: 0.8995 - accuracy: 0.5319 - val_loss: 0.7979 - val_accuracy: 0.5520\n",
            "Epoch 2/25\n",
            "60/60 - 0s - loss: 0.7619 - accuracy: 0.5825 - val_loss: 0.7248 - val_accuracy: 0.6386\n",
            "Epoch 3/25\n",
            "60/60 - 0s - loss: 0.6331 - accuracy: 0.7217 - val_loss: 0.5539 - val_accuracy: 0.7795\n",
            "Epoch 4/25\n",
            "60/60 - 0s - loss: 0.4698 - accuracy: 0.8227 - val_loss: 0.4400 - val_accuracy: 0.8344\n",
            "Epoch 5/25\n",
            "60/60 - 0s - loss: 0.3669 - accuracy: 0.8674 - val_loss: 0.3717 - val_accuracy: 0.8691\n",
            "Epoch 6/25\n",
            "60/60 - 0s - loss: 0.2977 - accuracy: 0.8994 - val_loss: 0.3275 - val_accuracy: 0.8892\n",
            "Epoch 7/25\n",
            "60/60 - 0s - loss: 0.2488 - accuracy: 0.9183 - val_loss: 0.3033 - val_accuracy: 0.8990\n",
            "Epoch 8/25\n",
            "60/60 - 0s - loss: 0.2118 - accuracy: 0.9315 - val_loss: 0.2729 - val_accuracy: 0.9130\n",
            "Epoch 9/25\n",
            "60/60 - 0s - loss: 0.1824 - accuracy: 0.9431 - val_loss: 0.2629 - val_accuracy: 0.9197\n",
            "Epoch 10/25\n",
            "60/60 - 0s - loss: 0.1583 - accuracy: 0.9515 - val_loss: 0.2434 - val_accuracy: 0.9289\n",
            "Epoch 11/25\n",
            "60/60 - 0s - loss: 0.1388 - accuracy: 0.9591 - val_loss: 0.2433 - val_accuracy: 0.9274\n",
            "Epoch 12/25\n",
            "60/60 - 0s - loss: 0.1244 - accuracy: 0.9642 - val_loss: 0.2282 - val_accuracy: 0.9352\n",
            "Epoch 13/25\n",
            "60/60 - 0s - loss: 0.1076 - accuracy: 0.9690 - val_loss: 0.2204 - val_accuracy: 0.9412\n",
            "Epoch 14/25\n",
            "60/60 - 0s - loss: 0.0962 - accuracy: 0.9728 - val_loss: 0.2176 - val_accuracy: 0.9416\n",
            "Epoch 15/25\n",
            "60/60 - 0s - loss: 0.0849 - accuracy: 0.9765 - val_loss: 0.2186 - val_accuracy: 0.9436\n",
            "Epoch 16/25\n",
            "60/60 - 0s - loss: 0.0752 - accuracy: 0.9794 - val_loss: 0.2095 - val_accuracy: 0.9468\n",
            "Epoch 17/25\n",
            "60/60 - 0s - loss: 0.0678 - accuracy: 0.9821 - val_loss: 0.2095 - val_accuracy: 0.9482\n",
            "Epoch 18/25\n",
            "60/60 - 0s - loss: 0.0592 - accuracy: 0.9847 - val_loss: 0.2057 - val_accuracy: 0.9512\n",
            "Epoch 19/25\n",
            "60/60 - 0s - loss: 0.0532 - accuracy: 0.9869 - val_loss: 0.2110 - val_accuracy: 0.9521\n",
            "Epoch 20/25\n",
            "60/60 - 0s - loss: 0.0476 - accuracy: 0.9886 - val_loss: 0.2084 - val_accuracy: 0.9525\n",
            "Epoch 21/25\n",
            "60/60 - 0s - loss: 0.0423 - accuracy: 0.9904 - val_loss: 0.2072 - val_accuracy: 0.9554\n",
            "Epoch 22/25\n",
            "60/60 - 0s - loss: 0.0383 - accuracy: 0.9913 - val_loss: 0.2137 - val_accuracy: 0.9556\n",
            "Epoch 23/25\n",
            "60/60 - 0s - loss: 0.0348 - accuracy: 0.9922 - val_loss: 0.2117 - val_accuracy: 0.9563\n",
            "Epoch 24/25\n",
            "60/60 - 0s - loss: 0.0313 - accuracy: 0.9931 - val_loss: 0.2117 - val_accuracy: 0.9564\n",
            "Epoch 25/25\n",
            "60/60 - 0s - loss: 0.0288 - accuracy: 0.9937 - val_loss: 0.2135 - val_accuracy: 0.9577\n",
            "593/593 - 1s - loss: 0.2179 - accuracy: 0.9566\n",
            "Score for fold 1: loss of 0.21788915991783142; accuracy of 95.6585943698883%\n",
            "Fold: 2\n",
            "Epoch 1/25\n",
            "60/60 - 1s - loss: 0.8500 - accuracy: 0.5916 - val_loss: 0.7387 - val_accuracy: 0.6689\n",
            "Epoch 2/25\n",
            "60/60 - 0s - loss: 0.6567 - accuracy: 0.7208 - val_loss: 0.5993 - val_accuracy: 0.7515\n",
            "Epoch 3/25\n",
            "60/60 - 0s - loss: 0.5118 - accuracy: 0.7951 - val_loss: 0.4910 - val_accuracy: 0.8077\n",
            "Epoch 4/25\n",
            "60/60 - 0s - loss: 0.4034 - accuracy: 0.8470 - val_loss: 0.4138 - val_accuracy: 0.8464\n",
            "Epoch 5/25\n",
            "60/60 - 0s - loss: 0.3272 - accuracy: 0.8809 - val_loss: 0.3631 - val_accuracy: 0.8715\n",
            "Epoch 6/25\n",
            "60/60 - 0s - loss: 0.2724 - accuracy: 0.9054 - val_loss: 0.3300 - val_accuracy: 0.8893\n",
            "Epoch 7/25\n",
            "60/60 - 0s - loss: 0.2322 - accuracy: 0.9211 - val_loss: 0.3050 - val_accuracy: 0.8985\n",
            "Epoch 8/25\n",
            "60/60 - 0s - loss: 0.1991 - accuracy: 0.9349 - val_loss: 0.2863 - val_accuracy: 0.9054\n",
            "Epoch 9/25\n",
            "60/60 - 0s - loss: 0.1728 - accuracy: 0.9452 - val_loss: 0.2703 - val_accuracy: 0.9168\n",
            "Epoch 10/25\n",
            "60/60 - 0s - loss: 0.1507 - accuracy: 0.9541 - val_loss: 0.2568 - val_accuracy: 0.9253\n",
            "Epoch 11/25\n",
            "60/60 - 0s - loss: 0.1328 - accuracy: 0.9603 - val_loss: 0.2511 - val_accuracy: 0.9287\n",
            "Epoch 12/25\n",
            "60/60 - 0s - loss: 0.1172 - accuracy: 0.9661 - val_loss: 0.2396 - val_accuracy: 0.9343\n",
            "Epoch 13/25\n",
            "60/60 - 0s - loss: 0.1026 - accuracy: 0.9709 - val_loss: 0.2343 - val_accuracy: 0.9380\n",
            "Epoch 14/25\n",
            "60/60 - 0s - loss: 0.0921 - accuracy: 0.9740 - val_loss: 0.2287 - val_accuracy: 0.9408\n",
            "Epoch 15/25\n",
            "60/60 - 0s - loss: 0.0825 - accuracy: 0.9768 - val_loss: 0.2265 - val_accuracy: 0.9428\n",
            "Epoch 16/25\n",
            "60/60 - 0s - loss: 0.0719 - accuracy: 0.9800 - val_loss: 0.2234 - val_accuracy: 0.9451\n",
            "Epoch 17/25\n",
            "60/60 - 0s - loss: 0.0641 - accuracy: 0.9819 - val_loss: 0.2225 - val_accuracy: 0.9474\n",
            "Epoch 18/25\n",
            "60/60 - 0s - loss: 0.0573 - accuracy: 0.9844 - val_loss: 0.2255 - val_accuracy: 0.9501\n",
            "Epoch 19/25\n",
            "60/60 - 0s - loss: 0.0508 - accuracy: 0.9865 - val_loss: 0.2266 - val_accuracy: 0.9477\n",
            "Epoch 20/25\n",
            "60/60 - 0s - loss: 0.0470 - accuracy: 0.9876 - val_loss: 0.2281 - val_accuracy: 0.9500\n",
            "Epoch 21/25\n",
            "60/60 - 0s - loss: 0.0413 - accuracy: 0.9894 - val_loss: 0.2206 - val_accuracy: 0.9529\n",
            "Epoch 22/25\n",
            "60/60 - 0s - loss: 0.0363 - accuracy: 0.9909 - val_loss: 0.2241 - val_accuracy: 0.9533\n",
            "Epoch 23/25\n",
            "60/60 - 0s - loss: 0.0333 - accuracy: 0.9916 - val_loss: 0.2270 - val_accuracy: 0.9540\n",
            "Epoch 24/25\n",
            "60/60 - 0s - loss: 0.0300 - accuracy: 0.9931 - val_loss: 0.2302 - val_accuracy: 0.9547\n",
            "Epoch 25/25\n",
            "60/60 - 0s - loss: 0.0271 - accuracy: 0.9935 - val_loss: 0.2348 - val_accuracy: 0.9542\n",
            "593/593 - 0s - loss: 0.2289 - accuracy: 0.9543\n",
            "Score for fold 2: loss of 0.22888164222240448; accuracy of 95.42649388313293%\n",
            "Fold: 3\n",
            "Epoch 1/25\n",
            "60/60 - 1s - loss: 0.8637 - accuracy: 0.5937 - val_loss: 0.7274 - val_accuracy: 0.6845\n",
            "Epoch 2/25\n",
            "60/60 - 0s - loss: 0.6487 - accuracy: 0.7299 - val_loss: 0.5870 - val_accuracy: 0.7709\n",
            "Epoch 3/25\n",
            "60/60 - 0s - loss: 0.5126 - accuracy: 0.8050 - val_loss: 0.4749 - val_accuracy: 0.8183\n",
            "Epoch 4/25\n",
            "60/60 - 0s - loss: 0.4053 - accuracy: 0.8540 - val_loss: 0.3998 - val_accuracy: 0.8483\n",
            "Epoch 5/25\n",
            "60/60 - 0s - loss: 0.3296 - accuracy: 0.8827 - val_loss: 0.3457 - val_accuracy: 0.8745\n",
            "Epoch 6/25\n",
            "60/60 - 0s - loss: 0.2733 - accuracy: 0.9060 - val_loss: 0.3113 - val_accuracy: 0.8912\n",
            "Epoch 7/25\n",
            "60/60 - 0s - loss: 0.2314 - accuracy: 0.9210 - val_loss: 0.2843 - val_accuracy: 0.9040\n",
            "Epoch 8/25\n",
            "60/60 - 0s - loss: 0.2007 - accuracy: 0.9329 - val_loss: 0.2699 - val_accuracy: 0.9138\n",
            "Epoch 9/25\n",
            "60/60 - 0s - loss: 0.1720 - accuracy: 0.9442 - val_loss: 0.2526 - val_accuracy: 0.9220\n",
            "Epoch 10/25\n",
            "60/60 - 0s - loss: 0.1496 - accuracy: 0.9527 - val_loss: 0.2414 - val_accuracy: 0.9288\n",
            "Epoch 11/25\n",
            "60/60 - 0s - loss: 0.1332 - accuracy: 0.9588 - val_loss: 0.2429 - val_accuracy: 0.9281\n",
            "Epoch 12/25\n",
            "60/60 - 0s - loss: 0.1175 - accuracy: 0.9639 - val_loss: 0.2231 - val_accuracy: 0.9390\n",
            "Epoch 13/25\n",
            "60/60 - 0s - loss: 0.1012 - accuracy: 0.9716 - val_loss: 0.2189 - val_accuracy: 0.9407\n",
            "Epoch 14/25\n",
            "60/60 - 0s - loss: 0.0895 - accuracy: 0.9756 - val_loss: 0.2172 - val_accuracy: 0.9424\n",
            "Epoch 15/25\n",
            "60/60 - 0s - loss: 0.0790 - accuracy: 0.9786 - val_loss: 0.2148 - val_accuracy: 0.9457\n",
            "Epoch 16/25\n",
            "60/60 - 0s - loss: 0.0700 - accuracy: 0.9817 - val_loss: 0.2107 - val_accuracy: 0.9496\n",
            "Epoch 17/25\n",
            "60/60 - 0s - loss: 0.0622 - accuracy: 0.9841 - val_loss: 0.2112 - val_accuracy: 0.9512\n",
            "Epoch 18/25\n",
            "60/60 - 0s - loss: 0.0581 - accuracy: 0.9849 - val_loss: 0.2113 - val_accuracy: 0.9517\n",
            "Epoch 19/25\n",
            "60/60 - 0s - loss: 0.0504 - accuracy: 0.9874 - val_loss: 0.2124 - val_accuracy: 0.9515\n",
            "Epoch 20/25\n",
            "60/60 - 0s - loss: 0.0452 - accuracy: 0.9889 - val_loss: 0.2128 - val_accuracy: 0.9538\n",
            "Epoch 21/25\n",
            "60/60 - 0s - loss: 0.0404 - accuracy: 0.9902 - val_loss: 0.2137 - val_accuracy: 0.9534\n",
            "Epoch 22/25\n",
            "60/60 - 0s - loss: 0.0355 - accuracy: 0.9914 - val_loss: 0.2151 - val_accuracy: 0.9541\n",
            "Epoch 23/25\n",
            "60/60 - 0s - loss: 0.0315 - accuracy: 0.9925 - val_loss: 0.2179 - val_accuracy: 0.9544\n",
            "Epoch 24/25\n",
            "60/60 - 0s - loss: 0.0288 - accuracy: 0.9933 - val_loss: 0.2204 - val_accuracy: 0.9556\n",
            "Epoch 25/25\n",
            "60/60 - 0s - loss: 0.0265 - accuracy: 0.9940 - val_loss: 0.2222 - val_accuracy: 0.9567\n",
            "593/593 - 0s - loss: 0.2254 - accuracy: 0.9547\n",
            "Score for fold 3: loss of 0.22535239160060883; accuracy of 95.46869397163391%\n",
            "Fold: 4\n",
            "Epoch 1/25\n",
            "60/60 - 1s - loss: 0.8713 - accuracy: 0.5625 - val_loss: 0.7612 - val_accuracy: 0.6740\n",
            "Epoch 2/25\n",
            "60/60 - 0s - loss: 0.6702 - accuracy: 0.7125 - val_loss: 0.5993 - val_accuracy: 0.7570\n",
            "Epoch 3/25\n",
            "60/60 - 0s - loss: 0.5164 - accuracy: 0.7982 - val_loss: 0.4826 - val_accuracy: 0.8123\n",
            "Epoch 4/25\n",
            "60/60 - 0s - loss: 0.4045 - accuracy: 0.8523 - val_loss: 0.4048 - val_accuracy: 0.8552\n",
            "Epoch 5/25\n",
            "60/60 - 0s - loss: 0.3273 - accuracy: 0.8848 - val_loss: 0.3515 - val_accuracy: 0.8776\n",
            "Epoch 6/25\n",
            "60/60 - 0s - loss: 0.2727 - accuracy: 0.9062 - val_loss: 0.3112 - val_accuracy: 0.8915\n",
            "Epoch 7/25\n",
            "60/60 - 0s - loss: 0.2301 - accuracy: 0.9228 - val_loss: 0.2835 - val_accuracy: 0.9041\n",
            "Epoch 8/25\n",
            "60/60 - 0s - loss: 0.1990 - accuracy: 0.9357 - val_loss: 0.2663 - val_accuracy: 0.9124\n",
            "Epoch 9/25\n",
            "60/60 - 0s - loss: 0.1733 - accuracy: 0.9453 - val_loss: 0.2511 - val_accuracy: 0.9173\n",
            "Epoch 10/25\n",
            "60/60 - 0s - loss: 0.1516 - accuracy: 0.9531 - val_loss: 0.2402 - val_accuracy: 0.9255\n",
            "Epoch 11/25\n",
            "60/60 - 0s - loss: 0.1326 - accuracy: 0.9603 - val_loss: 0.2283 - val_accuracy: 0.9314\n",
            "Epoch 12/25\n",
            "60/60 - 0s - loss: 0.1179 - accuracy: 0.9653 - val_loss: 0.2229 - val_accuracy: 0.9345\n",
            "Epoch 13/25\n",
            "60/60 - 0s - loss: 0.1044 - accuracy: 0.9697 - val_loss: 0.2176 - val_accuracy: 0.9376\n",
            "Epoch 14/25\n",
            "60/60 - 0s - loss: 0.0923 - accuracy: 0.9740 - val_loss: 0.2100 - val_accuracy: 0.9409\n",
            "Epoch 15/25\n",
            "60/60 - 0s - loss: 0.0814 - accuracy: 0.9779 - val_loss: 0.2092 - val_accuracy: 0.9436\n",
            "Epoch 16/25\n",
            "60/60 - 0s - loss: 0.0731 - accuracy: 0.9803 - val_loss: 0.2045 - val_accuracy: 0.9467\n",
            "Epoch 17/25\n",
            "60/60 - 0s - loss: 0.0642 - accuracy: 0.9834 - val_loss: 0.2036 - val_accuracy: 0.9476\n",
            "Epoch 18/25\n",
            "60/60 - 0s - loss: 0.0580 - accuracy: 0.9854 - val_loss: 0.2032 - val_accuracy: 0.9502\n",
            "Epoch 19/25\n",
            "60/60 - 0s - loss: 0.0513 - accuracy: 0.9872 - val_loss: 0.2063 - val_accuracy: 0.9506\n",
            "Epoch 20/25\n",
            "60/60 - 0s - loss: 0.0469 - accuracy: 0.9886 - val_loss: 0.2058 - val_accuracy: 0.9521\n",
            "Epoch 21/25\n",
            "60/60 - 0s - loss: 0.0423 - accuracy: 0.9894 - val_loss: 0.2076 - val_accuracy: 0.9529\n",
            "Epoch 22/25\n",
            "60/60 - 0s - loss: 0.0383 - accuracy: 0.9909 - val_loss: 0.2075 - val_accuracy: 0.9540\n",
            "Epoch 23/25\n",
            "60/60 - 0s - loss: 0.0338 - accuracy: 0.9923 - val_loss: 0.2097 - val_accuracy: 0.9536\n",
            "Epoch 24/25\n",
            "60/60 - 0s - loss: 0.0313 - accuracy: 0.9931 - val_loss: 0.2102 - val_accuracy: 0.9554\n",
            "Epoch 25/25\n",
            "60/60 - 0s - loss: 0.0281 - accuracy: 0.9939 - val_loss: 0.2120 - val_accuracy: 0.9544\n",
            "593/593 - 0s - loss: 0.2219 - accuracy: 0.9524\n",
            "Score for fold 4: loss of 0.22187191247940063; accuracy of 95.23658752441406%\n",
            "Fold: 5\n",
            "Epoch 1/25\n",
            "60/60 - 1s - loss: 0.8232 - accuracy: 0.6210 - val_loss: 0.7127 - val_accuracy: 0.6869\n",
            "Epoch 2/25\n",
            "60/60 - 0s - loss: 0.6300 - accuracy: 0.7392 - val_loss: 0.5722 - val_accuracy: 0.7718\n",
            "Epoch 3/25\n",
            "60/60 - 0s - loss: 0.4948 - accuracy: 0.8115 - val_loss: 0.4659 - val_accuracy: 0.8243\n",
            "Epoch 4/25\n",
            "60/60 - 0s - loss: 0.3928 - accuracy: 0.8552 - val_loss: 0.3923 - val_accuracy: 0.8587\n",
            "Epoch 5/25\n",
            "60/60 - 0s - loss: 0.3211 - accuracy: 0.8871 - val_loss: 0.3426 - val_accuracy: 0.8793\n",
            "Epoch 6/25\n",
            "60/60 - 0s - loss: 0.2669 - accuracy: 0.9071 - val_loss: 0.3064 - val_accuracy: 0.8949\n",
            "Epoch 7/25\n",
            "60/60 - 0s - loss: 0.2276 - accuracy: 0.9239 - val_loss: 0.2811 - val_accuracy: 0.9101\n",
            "Epoch 8/25\n",
            "60/60 - 0s - loss: 0.1949 - accuracy: 0.9379 - val_loss: 0.2621 - val_accuracy: 0.9197\n",
            "Epoch 9/25\n",
            "60/60 - 0s - loss: 0.1710 - accuracy: 0.9463 - val_loss: 0.2496 - val_accuracy: 0.9246\n",
            "Epoch 10/25\n",
            "60/60 - 0s - loss: 0.1474 - accuracy: 0.9549 - val_loss: 0.2358 - val_accuracy: 0.9285\n",
            "Epoch 11/25\n",
            "60/60 - 0s - loss: 0.1293 - accuracy: 0.9618 - val_loss: 0.2279 - val_accuracy: 0.9327\n",
            "Epoch 12/25\n",
            "60/60 - 0s - loss: 0.1148 - accuracy: 0.9662 - val_loss: 0.2221 - val_accuracy: 0.9375\n",
            "Epoch 13/25\n",
            "60/60 - 0s - loss: 0.1028 - accuracy: 0.9706 - val_loss: 0.2162 - val_accuracy: 0.9412\n",
            "Epoch 14/25\n",
            "60/60 - 0s - loss: 0.0894 - accuracy: 0.9753 - val_loss: 0.2109 - val_accuracy: 0.9434\n",
            "Epoch 15/25\n",
            "60/60 - 0s - loss: 0.0787 - accuracy: 0.9789 - val_loss: 0.2152 - val_accuracy: 0.9447\n",
            "Epoch 16/25\n",
            "60/60 - 0s - loss: 0.0702 - accuracy: 0.9816 - val_loss: 0.2090 - val_accuracy: 0.9481\n",
            "Epoch 17/25\n",
            "60/60 - 0s - loss: 0.0619 - accuracy: 0.9843 - val_loss: 0.2058 - val_accuracy: 0.9506\n",
            "Epoch 18/25\n",
            "60/60 - 0s - loss: 0.0551 - accuracy: 0.9865 - val_loss: 0.2067 - val_accuracy: 0.9515\n",
            "Epoch 19/25\n",
            "60/60 - 0s - loss: 0.0496 - accuracy: 0.9879 - val_loss: 0.2077 - val_accuracy: 0.9505\n",
            "Epoch 20/25\n",
            "60/60 - 0s - loss: 0.0445 - accuracy: 0.9896 - val_loss: 0.2052 - val_accuracy: 0.9528\n",
            "Epoch 21/25\n",
            "60/60 - 0s - loss: 0.0394 - accuracy: 0.9909 - val_loss: 0.2070 - val_accuracy: 0.9540\n",
            "Epoch 22/25\n",
            "60/60 - 0s - loss: 0.0364 - accuracy: 0.9920 - val_loss: 0.2106 - val_accuracy: 0.9549\n",
            "Epoch 23/25\n",
            "60/60 - 0s - loss: 0.0329 - accuracy: 0.9927 - val_loss: 0.2101 - val_accuracy: 0.9552\n",
            "Epoch 24/25\n",
            "60/60 - 0s - loss: 0.0294 - accuracy: 0.9937 - val_loss: 0.2183 - val_accuracy: 0.9550\n",
            "Epoch 25/25\n",
            "60/60 - 0s - loss: 0.0272 - accuracy: 0.9943 - val_loss: 0.2155 - val_accuracy: 0.9559\n",
            "593/593 - 0s - loss: 0.2363 - accuracy: 0.9538\n",
            "Score for fold 5: loss of 0.23634059727191925; accuracy of 95.37901282310486%\n",
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "------------------------------------------------------------------------\n",
            "> Fold 1 - Loss: 0.21788915991783142 - Accuracy: 95.6585943698883%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 2 - Loss: 0.22888164222240448 - Accuracy: 95.42649388313293%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 3 - Loss: 0.22535239160060883 - Accuracy: 95.46869397163391%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 4 - Loss: 0.22187191247940063 - Accuracy: 95.23658752441406%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 5 - Loss: 0.23634059727191925 - Accuracy: 95.37901282310486%\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> Accuracy: 95.43387651443481 (+- 0.13689254423826278)\n",
            "> Loss: 0.22606714069843292\n",
            "------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}