{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "modelTrainTestProteinDomainsRNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oGiut-5Yl5j"
      },
      "source": [
        "import time\n",
        "import csv\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import tensorflow.keras.backend as K\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gGWAJT3SBBy"
      },
      "source": [
        "#\"\"\" Loading, padding and one-hot encoding of the data\"\"\"\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/dbosnacki/HelisDeepLearningCourse/main/cath-domain-description-file-v2_4ProcessedForNN.tsv' \n",
        "df = pd.read_csv(url, delimiter = \"\\t\", header=None)\n",
        "npd = df[3].to_numpy()\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5sFWxVtYqHs"
      },
      "source": [
        "# find the maximal sequence length\n",
        "maxSeqLength = 0\n",
        "for sequence in npd:\n",
        "    l = len(sequence)\n",
        "    if l > maxSeqLength:\n",
        "      maxSeqLength = l \n",
        "\n",
        "data = list()\n",
        "for i in range(len(npd)):\n",
        "  alph_as_num = np.array(list(npd[i])).view(np.int32)\n",
        "  data.append(np.array(list(npd[i])).view(np.int32))\n",
        "\n",
        "#print(len(data))\n",
        "#print(data[1330])\n",
        "\n",
        "padded_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    data, padding=\"post\"\n",
        ")\n",
        "#print(padded_inputs)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xw9BbM_KWUe5",
        "outputId": "2d62d0db-5267-4d6c-9751-0ecd24bbc914",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# padd the sequences with spaces to get equal length\n",
        "# dataset = []\n",
        "\n",
        "# for sequence in sequences:\n",
        "#     dataset.append(list(sequence.ljust(maxSeqLength, ' ')))\n",
        "    \n",
        "# #one hot encoding of the data\n",
        "# cat = OneHotEncoder()\n",
        "# dataset = cat.fit_transform(dataset).toarray()\n",
        "\n",
        "labels = list(df[2])    \n",
        "\n",
        "X = padded_inputs\n",
        "y = np.array(labels)\n",
        "\n",
        "print(X.shape)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "accuracy_per_fold = []\n",
        "loss_per_fold = []\n",
        "\n",
        "fold_no = 1\n",
        "seed = 10\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(94785, 70)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvvZYrjKSSs8",
        "outputId": "1168dcc0-d301-4623-bffd-984f5e93e52b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for train_index, val_index in skf.split(X_train, y_train):\n",
        "    \n",
        "    print('Fold: ' + str(fold_no))\n",
        "    \n",
        "\n",
        "    # Define RNN model \n",
        "    model = keras.Sequential(\n",
        "        [\n",
        "           layers.Embedding(128, 8),\n",
        "           layers.LSTM(64, name=\"rnn1\"),\n",
        "           #layers.Dense(64, activation=\"relu\", name=\"layer2\"),\n",
        "           layers.Dense(3, activation=\"softmax\", name=\"output\"),\n",
        "        ]\n",
        "    )\n",
        "    \n",
        "    # model.summary()\n",
        "\n",
        "    model.compile(\n",
        "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "        metrics=['accuracy'],\n",
        "        optimizer='adam',\n",
        "    )\n",
        "    \n",
        "\n",
        "    history = model.fit(X_train[train_index], \n",
        "                        y_train[train_index], \n",
        "                        batch_size = 128, \n",
        "                        epochs = 100, \n",
        "                        #class_weight = class_weight, \n",
        "                        validation_data = (X_train[val_index], y_train[val_index]),\n",
        "                        #callbacks = callbacks_list,\n",
        "                        verbose = 2)\n",
        "    \n",
        "    scores = model.evaluate(X_test, y_test, verbose=2)\n",
        "    \n",
        "    #model.save(newpath + r'\\fold-' + str(fold_no) + '.hdf5') \n",
        "\n",
        "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "    accuracy_per_fold.append(scores[1] * 100)\n",
        "    loss_per_fold.append(scores[0])\n",
        "\n",
        "    # Increase fold number\n",
        "    fold_no = fold_no + 1\n",
        "\n",
        "# Average scores\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(len(accuracy_per_fold)):\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {accuracy_per_fold[i]}%')\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Average scores for all folds:')\n",
        "print(f'> Accuracy: {np.mean(accuracy_per_fold)} (+- {np.std(accuracy_per_fold)})')\n",
        "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "print('------------------------------------------------------------------------')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold: 2\n",
            "Epoch 1/100\n",
            "474/474 - 3s - loss: 0.9461 - accuracy: 0.5693 - val_loss: 0.8606 - val_accuracy: 0.6083\n",
            "Epoch 2/100\n",
            "474/474 - 3s - loss: 0.8556 - accuracy: 0.6039 - val_loss: 0.8481 - val_accuracy: 0.6064\n",
            "Epoch 3/100\n",
            "474/474 - 3s - loss: 0.8423 - accuracy: 0.6098 - val_loss: 0.8444 - val_accuracy: 0.6186\n",
            "Epoch 4/100\n",
            "474/474 - 3s - loss: 0.8265 - accuracy: 0.6202 - val_loss: 0.8102 - val_accuracy: 0.6357\n",
            "Epoch 5/100\n",
            "474/474 - 3s - loss: 0.8084 - accuracy: 0.6354 - val_loss: 0.7988 - val_accuracy: 0.6394\n",
            "Epoch 6/100\n",
            "474/474 - 3s - loss: 0.7930 - accuracy: 0.6433 - val_loss: 0.7846 - val_accuracy: 0.6466\n",
            "Epoch 7/100\n",
            "474/474 - 3s - loss: 0.7742 - accuracy: 0.6547 - val_loss: 0.7577 - val_accuracy: 0.6637\n",
            "Epoch 8/100\n",
            "474/474 - 3s - loss: 0.7543 - accuracy: 0.6664 - val_loss: 0.7408 - val_accuracy: 0.6782\n",
            "Epoch 9/100\n",
            "474/474 - 3s - loss: 0.7315 - accuracy: 0.6848 - val_loss: 0.7199 - val_accuracy: 0.6925\n",
            "Epoch 10/100\n",
            "474/474 - 3s - loss: 0.7161 - accuracy: 0.6941 - val_loss: 0.7158 - val_accuracy: 0.6873\n",
            "Epoch 11/100\n",
            "474/474 - 3s - loss: 0.6942 - accuracy: 0.7065 - val_loss: 0.6749 - val_accuracy: 0.7184\n",
            "Epoch 12/100\n",
            "474/474 - 3s - loss: 0.6657 - accuracy: 0.7226 - val_loss: 0.6655 - val_accuracy: 0.7199\n",
            "Epoch 13/100\n",
            "474/474 - 3s - loss: 0.6451 - accuracy: 0.7345 - val_loss: 0.6333 - val_accuracy: 0.7415\n",
            "Epoch 14/100\n",
            "474/474 - 3s - loss: 0.6234 - accuracy: 0.7466 - val_loss: 0.6208 - val_accuracy: 0.7523\n",
            "Epoch 15/100\n",
            "474/474 - 3s - loss: 0.6077 - accuracy: 0.7553 - val_loss: 0.6001 - val_accuracy: 0.7614\n",
            "Epoch 16/100\n",
            "474/474 - 3s - loss: 0.5874 - accuracy: 0.7647 - val_loss: 0.6170 - val_accuracy: 0.7498\n",
            "Epoch 17/100\n",
            "474/474 - 3s - loss: 0.5662 - accuracy: 0.7739 - val_loss: 0.5753 - val_accuracy: 0.7669\n",
            "Epoch 18/100\n",
            "474/474 - 3s - loss: 0.5550 - accuracy: 0.7806 - val_loss: 0.5537 - val_accuracy: 0.7868\n",
            "Epoch 19/100\n",
            "474/474 - 3s - loss: 0.5398 - accuracy: 0.7874 - val_loss: 0.5693 - val_accuracy: 0.7781\n",
            "Epoch 20/100\n",
            "474/474 - 3s - loss: 0.5180 - accuracy: 0.7973 - val_loss: 0.5321 - val_accuracy: 0.7924\n",
            "Epoch 21/100\n",
            "474/474 - 3s - loss: 0.5051 - accuracy: 0.8028 - val_loss: 0.5507 - val_accuracy: 0.7829\n",
            "Epoch 22/100\n",
            "474/474 - 3s - loss: 0.5007 - accuracy: 0.8045 - val_loss: 0.5185 - val_accuracy: 0.7999\n",
            "Epoch 23/100\n",
            "474/474 - 3s - loss: 0.4801 - accuracy: 0.8131 - val_loss: 0.5143 - val_accuracy: 0.8024\n",
            "Epoch 24/100\n",
            "474/474 - 3s - loss: 0.4688 - accuracy: 0.8198 - val_loss: 0.4955 - val_accuracy: 0.8108\n",
            "Epoch 25/100\n",
            "474/474 - 3s - loss: 0.4539 - accuracy: 0.8263 - val_loss: 0.5125 - val_accuracy: 0.8047\n",
            "Epoch 26/100\n",
            "474/474 - 3s - loss: 0.4447 - accuracy: 0.8293 - val_loss: 0.4844 - val_accuracy: 0.8163\n",
            "Epoch 27/100\n",
            "474/474 - 3s - loss: 0.4363 - accuracy: 0.8349 - val_loss: 0.4771 - val_accuracy: 0.8249\n",
            "Epoch 28/100\n",
            "474/474 - 3s - loss: 0.4242 - accuracy: 0.8401 - val_loss: 0.4926 - val_accuracy: 0.8156\n",
            "Epoch 29/100\n",
            "474/474 - 3s - loss: 0.4136 - accuracy: 0.8443 - val_loss: 0.4601 - val_accuracy: 0.8290\n",
            "Epoch 30/100\n",
            "474/474 - 3s - loss: 0.4079 - accuracy: 0.8487 - val_loss: 0.4526 - val_accuracy: 0.8371\n",
            "Epoch 31/100\n",
            "474/474 - 3s - loss: 0.3990 - accuracy: 0.8514 - val_loss: 0.4887 - val_accuracy: 0.8243\n",
            "Epoch 32/100\n",
            "474/474 - 3s - loss: 0.4247 - accuracy: 0.8393 - val_loss: 0.4678 - val_accuracy: 0.8278\n",
            "Epoch 33/100\n",
            "474/474 - 3s - loss: 0.3849 - accuracy: 0.8575 - val_loss: 0.4499 - val_accuracy: 0.8375\n",
            "Epoch 34/100\n",
            "474/474 - 3s - loss: 0.3767 - accuracy: 0.8612 - val_loss: 0.4419 - val_accuracy: 0.8450\n",
            "Epoch 35/100\n",
            "474/474 - 3s - loss: 0.3710 - accuracy: 0.8634 - val_loss: 0.4462 - val_accuracy: 0.8402\n",
            "Epoch 36/100\n",
            "474/474 - 3s - loss: 0.3628 - accuracy: 0.8664 - val_loss: 0.4659 - val_accuracy: 0.8369\n",
            "Epoch 37/100\n",
            "474/474 - 3s - loss: 0.3585 - accuracy: 0.8699 - val_loss: 0.4214 - val_accuracy: 0.8549\n",
            "Epoch 38/100\n",
            "474/474 - 3s - loss: 0.3420 - accuracy: 0.8756 - val_loss: 0.4354 - val_accuracy: 0.8483\n",
            "Epoch 39/100\n",
            "474/474 - 3s - loss: 0.3486 - accuracy: 0.8721 - val_loss: 0.4136 - val_accuracy: 0.8534\n",
            "Epoch 40/100\n",
            "474/474 - 3s - loss: 0.3436 - accuracy: 0.8749 - val_loss: 0.4235 - val_accuracy: 0.8506\n",
            "Epoch 41/100\n",
            "474/474 - 3s - loss: 0.3309 - accuracy: 0.8807 - val_loss: 0.4143 - val_accuracy: 0.8559\n",
            "Epoch 42/100\n",
            "474/474 - 3s - loss: 0.3262 - accuracy: 0.8822 - val_loss: 0.3994 - val_accuracy: 0.8622\n",
            "Epoch 43/100\n",
            "474/474 - 3s - loss: 0.3271 - accuracy: 0.8810 - val_loss: 0.4109 - val_accuracy: 0.8586\n",
            "Epoch 44/100\n",
            "474/474 - 3s - loss: 0.3225 - accuracy: 0.8833 - val_loss: 0.4036 - val_accuracy: 0.8635\n",
            "Epoch 45/100\n",
            "474/474 - 3s - loss: 0.3101 - accuracy: 0.8883 - val_loss: 0.4126 - val_accuracy: 0.8586\n",
            "Epoch 46/100\n",
            "474/474 - 3s - loss: 0.3047 - accuracy: 0.8900 - val_loss: 0.3978 - val_accuracy: 0.8659\n",
            "Epoch 47/100\n",
            "474/474 - 3s - loss: 0.3004 - accuracy: 0.8920 - val_loss: 0.3956 - val_accuracy: 0.8710\n",
            "Epoch 48/100\n",
            "474/474 - 3s - loss: 0.2921 - accuracy: 0.8956 - val_loss: 0.3853 - val_accuracy: 0.8717\n",
            "Epoch 49/100\n",
            "474/474 - 3s - loss: 0.2978 - accuracy: 0.8936 - val_loss: 0.3783 - val_accuracy: 0.8783\n",
            "Epoch 50/100\n",
            "474/474 - 3s - loss: 0.2909 - accuracy: 0.8958 - val_loss: 0.3815 - val_accuracy: 0.8704\n",
            "Epoch 51/100\n",
            "474/474 - 3s - loss: 0.2842 - accuracy: 0.8981 - val_loss: 0.3957 - val_accuracy: 0.8679\n",
            "Epoch 52/100\n",
            "474/474 - 3s - loss: 0.2786 - accuracy: 0.9002 - val_loss: 0.4037 - val_accuracy: 0.8679\n",
            "Epoch 53/100\n",
            "474/474 - 3s - loss: 0.2755 - accuracy: 0.9015 - val_loss: 0.3869 - val_accuracy: 0.8696\n",
            "Epoch 54/100\n",
            "474/474 - 3s - loss: 0.2693 - accuracy: 0.9041 - val_loss: 0.3618 - val_accuracy: 0.8814\n",
            "Epoch 55/100\n",
            "474/474 - 3s - loss: 0.2719 - accuracy: 0.9033 - val_loss: 0.4051 - val_accuracy: 0.8614\n",
            "Epoch 56/100\n",
            "474/474 - 3s - loss: 0.2834 - accuracy: 0.8998 - val_loss: 0.3781 - val_accuracy: 0.8760\n",
            "Epoch 57/100\n",
            "474/474 - 3s - loss: 0.2662 - accuracy: 0.9062 - val_loss: 0.3701 - val_accuracy: 0.8795\n",
            "Epoch 58/100\n",
            "474/474 - 3s - loss: 0.2562 - accuracy: 0.9093 - val_loss: 0.3619 - val_accuracy: 0.8829\n",
            "Epoch 59/100\n",
            "474/474 - 3s - loss: 0.2636 - accuracy: 0.9072 - val_loss: 0.3703 - val_accuracy: 0.8792\n",
            "Epoch 60/100\n",
            "474/474 - 3s - loss: 0.2510 - accuracy: 0.9118 - val_loss: 0.3540 - val_accuracy: 0.8859\n",
            "Epoch 61/100\n",
            "474/474 - 3s - loss: 0.2463 - accuracy: 0.9125 - val_loss: 0.3820 - val_accuracy: 0.8727\n",
            "Epoch 62/100\n",
            "474/474 - 3s - loss: 0.2431 - accuracy: 0.9142 - val_loss: 0.3881 - val_accuracy: 0.8699\n",
            "Epoch 63/100\n",
            "474/474 - 3s - loss: 0.2457 - accuracy: 0.9154 - val_loss: 0.3617 - val_accuracy: 0.8872\n",
            "Epoch 64/100\n",
            "474/474 - 3s - loss: 0.2384 - accuracy: 0.9181 - val_loss: 0.4058 - val_accuracy: 0.8678\n",
            "Epoch 65/100\n",
            "474/474 - 3s - loss: 0.2598 - accuracy: 0.9093 - val_loss: 0.3779 - val_accuracy: 0.8818\n",
            "Epoch 66/100\n",
            "474/474 - 3s - loss: 0.2266 - accuracy: 0.9215 - val_loss: 0.3594 - val_accuracy: 0.8888\n",
            "Epoch 67/100\n",
            "474/474 - 3s - loss: 0.2313 - accuracy: 0.9203 - val_loss: 0.3448 - val_accuracy: 0.8921\n",
            "Epoch 68/100\n",
            "474/474 - 3s - loss: 0.2308 - accuracy: 0.9199 - val_loss: 0.3591 - val_accuracy: 0.8865\n",
            "Epoch 69/100\n",
            "474/474 - 3s - loss: 0.2188 - accuracy: 0.9241 - val_loss: 0.3539 - val_accuracy: 0.8888\n",
            "Epoch 70/100\n",
            "474/474 - 3s - loss: 0.2285 - accuracy: 0.9202 - val_loss: 0.3712 - val_accuracy: 0.8793\n",
            "Epoch 71/100\n",
            "474/474 - 3s - loss: 0.2180 - accuracy: 0.9253 - val_loss: 0.3445 - val_accuracy: 0.8956\n",
            "Epoch 72/100\n",
            "474/474 - 3s - loss: 0.2272 - accuracy: 0.9216 - val_loss: 0.3634 - val_accuracy: 0.8842\n",
            "Epoch 73/100\n",
            "474/474 - 3s - loss: 0.2272 - accuracy: 0.9222 - val_loss: 0.3398 - val_accuracy: 0.8959\n",
            "Epoch 74/100\n",
            "474/474 - 3s - loss: 0.2040 - accuracy: 0.9303 - val_loss: 0.3315 - val_accuracy: 0.8998\n",
            "Epoch 75/100\n",
            "474/474 - 3s - loss: 0.1999 - accuracy: 0.9308 - val_loss: 0.3838 - val_accuracy: 0.8816\n",
            "Epoch 76/100\n",
            "474/474 - 3s - loss: 0.2267 - accuracy: 0.9213 - val_loss: 0.3360 - val_accuracy: 0.8977\n",
            "Epoch 77/100\n",
            "474/474 - 3s - loss: 0.1972 - accuracy: 0.9327 - val_loss: 0.3547 - val_accuracy: 0.8939\n",
            "Epoch 78/100\n",
            "474/474 - 3s - loss: 0.1992 - accuracy: 0.9322 - val_loss: 0.3484 - val_accuracy: 0.8956\n",
            "Epoch 79/100\n",
            "474/474 - 3s - loss: 0.2074 - accuracy: 0.9292 - val_loss: 0.3966 - val_accuracy: 0.8794\n",
            "Epoch 80/100\n",
            "474/474 - 3s - loss: 0.2251 - accuracy: 0.9230 - val_loss: 0.3524 - val_accuracy: 0.8928\n",
            "Epoch 81/100\n",
            "474/474 - 3s - loss: 0.1909 - accuracy: 0.9356 - val_loss: 0.3372 - val_accuracy: 0.8983\n",
            "Epoch 82/100\n",
            "474/474 - 3s - loss: 0.1899 - accuracy: 0.9365 - val_loss: 0.3942 - val_accuracy: 0.8823\n",
            "Epoch 83/100\n",
            "474/474 - 3s - loss: 0.1991 - accuracy: 0.9314 - val_loss: 0.3441 - val_accuracy: 0.8962\n",
            "Epoch 84/100\n",
            "474/474 - 3s - loss: 0.2144 - accuracy: 0.9245 - val_loss: 0.3883 - val_accuracy: 0.8776\n",
            "Epoch 85/100\n",
            "474/474 - 3s - loss: 0.1820 - accuracy: 0.9382 - val_loss: 0.3199 - val_accuracy: 0.9116\n",
            "Epoch 86/100\n",
            "474/474 - 3s - loss: 0.1871 - accuracy: 0.9352 - val_loss: 0.3787 - val_accuracy: 0.8892\n",
            "Epoch 87/100\n",
            "474/474 - 3s - loss: 0.1912 - accuracy: 0.9357 - val_loss: 0.3514 - val_accuracy: 0.8989\n",
            "Epoch 88/100\n",
            "474/474 - 3s - loss: 0.2040 - accuracy: 0.9289 - val_loss: 0.3686 - val_accuracy: 0.8944\n",
            "Epoch 89/100\n",
            "474/474 - 3s - loss: 0.2048 - accuracy: 0.9311 - val_loss: 0.3367 - val_accuracy: 0.9036\n",
            "Epoch 90/100\n",
            "474/474 - 3s - loss: 0.1858 - accuracy: 0.9367 - val_loss: 0.3329 - val_accuracy: 0.9027\n",
            "Epoch 91/100\n",
            "474/474 - 3s - loss: 0.1780 - accuracy: 0.9400 - val_loss: 0.3614 - val_accuracy: 0.8941\n",
            "Epoch 92/100\n",
            "474/474 - 3s - loss: 0.1882 - accuracy: 0.9358 - val_loss: 0.3465 - val_accuracy: 0.9043\n",
            "Epoch 93/100\n",
            "474/474 - 3s - loss: 0.1788 - accuracy: 0.9389 - val_loss: 0.3414 - val_accuracy: 0.9008\n",
            "Epoch 94/100\n",
            "474/474 - 3s - loss: 0.1833 - accuracy: 0.9382 - val_loss: 0.3562 - val_accuracy: 0.8958\n",
            "Epoch 95/100\n",
            "474/474 - 3s - loss: 0.1816 - accuracy: 0.9383 - val_loss: 0.3609 - val_accuracy: 0.8969\n",
            "Epoch 96/100\n",
            "474/474 - 3s - loss: 0.1717 - accuracy: 0.9431 - val_loss: 0.3297 - val_accuracy: 0.9112\n",
            "Epoch 97/100\n",
            "474/474 - 3s - loss: 0.1831 - accuracy: 0.9372 - val_loss: 0.3253 - val_accuracy: 0.9087\n",
            "Epoch 98/100\n",
            "474/474 - 3s - loss: 0.1884 - accuracy: 0.9355 - val_loss: 0.3442 - val_accuracy: 0.9013\n",
            "Epoch 99/100\n",
            "474/474 - 3s - loss: 0.1661 - accuracy: 0.9444 - val_loss: 0.3730 - val_accuracy: 0.8934\n",
            "Epoch 100/100\n",
            "474/474 - 3s - loss: 0.1696 - accuracy: 0.9430 - val_loss: 0.3355 - val_accuracy: 0.9047\n",
            "593/593 - 2s - loss: 0.3423 - accuracy: 0.9014\n",
            "Score for fold 2: loss of 0.34233078360557556; accuracy of 90.14084339141846%\n",
            "Fold: 3\n",
            "Epoch 1/100\n",
            "474/474 - 4s - loss: 0.9421 - accuracy: 0.5735 - val_loss: 0.8716 - val_accuracy: 0.6089\n",
            "Epoch 2/100\n",
            "474/474 - 3s - loss: 0.8555 - accuracy: 0.6011 - val_loss: 0.8537 - val_accuracy: 0.5946\n",
            "Epoch 3/100\n",
            "474/474 - 3s - loss: 0.8430 - accuracy: 0.6072 - val_loss: 0.8376 - val_accuracy: 0.6180\n",
            "Epoch 4/100\n",
            "474/474 - 3s - loss: 0.8263 - accuracy: 0.6187 - val_loss: 0.8189 - val_accuracy: 0.6238\n",
            "Epoch 5/100\n",
            "474/474 - 3s - loss: 0.8062 - accuracy: 0.6317 - val_loss: 0.8020 - val_accuracy: 0.6382\n",
            "Epoch 6/100\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}