{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "modelTrainTestProteinDomainsRNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oGiut-5Yl5j"
      },
      "source": [
        "import time\n",
        "import csv\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import tensorflow.keras.backend as K\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gGWAJT3SBBy"
      },
      "source": [
        "#\"\"\" Loading, padding and one-hot encoding of the data\"\"\"\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/dbosnacki/HelisDeepLearningCourse/main/cath-domain-description-file-v2_4ProcessedForNN.tsv' \n",
        "df = pd.read_csv(url, delimiter = \"\\t\", header=None)\n",
        "npd = df[3].to_numpy()\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5sFWxVtYqHs"
      },
      "source": [
        "# find the maximal sequence length\n",
        "maxSeqLength = 0\n",
        "for sequence in npd:\n",
        "    l = len(sequence)\n",
        "    if l > maxSeqLength:\n",
        "      maxSeqLength = l \n",
        "\n",
        "data = list()\n",
        "for i in range(len(npd)):\n",
        "  alph_as_num = np.array(list(npd[i])).view(np.int32)\n",
        "  data.append(np.array(list(npd[i])).view(np.int32))\n",
        "\n",
        "#print(len(data))\n",
        "#print(data[1330])\n",
        "\n",
        "padded_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    data, padding=\"post\"\n",
        ")\n",
        "#print(padded_inputs)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xw9BbM_KWUe5",
        "outputId": "2d62d0db-5267-4d6c-9751-0ecd24bbc914",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# padd the sequences with spaces to get equal length\n",
        "# dataset = []\n",
        "\n",
        "# for sequence in sequences:\n",
        "#     dataset.append(list(sequence.ljust(maxSeqLength, ' ')))\n",
        "    \n",
        "# #one hot encoding of the data\n",
        "# cat = OneHotEncoder()\n",
        "# dataset = cat.fit_transform(dataset).toarray()\n",
        "\n",
        "labels = list(df[2])    \n",
        "\n",
        "X = padded_inputs\n",
        "y = np.array(labels)\n",
        "\n",
        "print(X.shape)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "accuracy_per_fold = []\n",
        "loss_per_fold = []\n",
        "\n",
        "fold_no = 1\n",
        "seed = 10\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(94785, 70)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvvZYrjKSSs8",
        "outputId": "1ef6fe43-360c-43a7-d209-459612ef5461",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for train_index, val_index in skf.split(X_train, y_train):\n",
        "    \n",
        "    print('Fold: ' + str(fold_no))\n",
        "    \n",
        "\n",
        "    # Define RNN model \n",
        "    model = keras.Sequential(\n",
        "        [\n",
        "           layers.Embedding(128, 64),\n",
        "           layers.Bidirectional(layers.LSTM(64, dropout = 0.2, name=\"rnn1\")),\n",
        "           #layers.Dense(64, activation=\"relu\", name=\"layer2\"),\n",
        "           layers.Dense(3, activation=\"softmax\", name=\"output\"),\n",
        "        ]\n",
        "    )\n",
        "    \n",
        "    # model.summary()\n",
        "\n",
        "    model.compile(\n",
        "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "        metrics=['accuracy'],\n",
        "        optimizer='adam',\n",
        "    )\n",
        "    \n",
        "\n",
        "    history = model.fit(X_train[train_index], \n",
        "                        y_train[train_index], \n",
        "                        batch_size = 128, \n",
        "                        epochs = 100, \n",
        "                        #class_weight = class_weight, \n",
        "                        validation_data = (X_train[val_index], y_train[val_index]),\n",
        "                        #callbacks = callbacks_list,\n",
        "                        verbose = 2)\n",
        "    \n",
        "    scores = model.evaluate(X_test, y_test, verbose=2)\n",
        "    \n",
        "    #model.save(newpath + r'\\fold-' + str(fold_no) + '.hdf5') \n",
        "\n",
        "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "    accuracy_per_fold.append(scores[1] * 100)\n",
        "    loss_per_fold.append(scores[0])\n",
        "\n",
        "    # Increase fold number\n",
        "    fold_no = fold_no + 1\n",
        "\n",
        "# Average scores\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(len(accuracy_per_fold)):\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {accuracy_per_fold[i]}%')\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Average scores for all folds:')\n",
        "print(f'> Accuracy: {np.mean(accuracy_per_fold)} (+- {np.std(accuracy_per_fold)})')\n",
        "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "print('------------------------------------------------------------------------')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold: 7\n",
            "Epoch 1/100\n",
            "474/474 - 6s - loss: 0.8749 - accuracy: 0.5986 - val_loss: 0.8265 - val_accuracy: 0.6169\n",
            "Epoch 2/100\n",
            "474/474 - 5s - loss: 0.8091 - accuracy: 0.6340 - val_loss: 0.7719 - val_accuracy: 0.6551\n",
            "Epoch 3/100\n",
            "474/474 - 5s - loss: 0.7455 - accuracy: 0.6725 - val_loss: 0.6992 - val_accuracy: 0.7017\n",
            "Epoch 4/100\n",
            "474/474 - 5s - loss: 0.6752 - accuracy: 0.7127 - val_loss: 0.6255 - val_accuracy: 0.7382\n",
            "Epoch 5/100\n",
            "474/474 - 5s - loss: 0.6106 - accuracy: 0.7464 - val_loss: 0.5561 - val_accuracy: 0.7751\n",
            "Epoch 6/100\n",
            "474/474 - 5s - loss: 0.5491 - accuracy: 0.7760 - val_loss: 0.5177 - val_accuracy: 0.7968\n",
            "Epoch 7/100\n",
            "474/474 - 5s - loss: 0.4984 - accuracy: 0.8019 - val_loss: 0.4665 - val_accuracy: 0.8212\n",
            "Epoch 8/100\n",
            "474/474 - 6s - loss: 0.4528 - accuracy: 0.8245 - val_loss: 0.4325 - val_accuracy: 0.8386\n",
            "Epoch 9/100\n",
            "474/474 - 6s - loss: 0.4193 - accuracy: 0.8407 - val_loss: 0.4085 - val_accuracy: 0.8495\n",
            "Epoch 10/100\n",
            "474/474 - 5s - loss: 0.3874 - accuracy: 0.8534 - val_loss: 0.3906 - val_accuracy: 0.8543\n",
            "Epoch 11/100\n",
            "474/474 - 5s - loss: 0.3606 - accuracy: 0.8647 - val_loss: 0.3609 - val_accuracy: 0.8675\n",
            "Epoch 12/100\n",
            "474/474 - 5s - loss: 0.3390 - accuracy: 0.8735 - val_loss: 0.3481 - val_accuracy: 0.8764\n",
            "Epoch 13/100\n",
            "474/474 - 5s - loss: 0.3167 - accuracy: 0.8832 - val_loss: 0.3298 - val_accuracy: 0.8802\n",
            "Epoch 14/100\n",
            "474/474 - 5s - loss: 0.3006 - accuracy: 0.8918 - val_loss: 0.3133 - val_accuracy: 0.8888\n",
            "Epoch 15/100\n",
            "474/474 - 5s - loss: 0.2857 - accuracy: 0.8972 - val_loss: 0.3133 - val_accuracy: 0.8868\n",
            "Epoch 16/100\n",
            "474/474 - 5s - loss: 0.2699 - accuracy: 0.9029 - val_loss: 0.3035 - val_accuracy: 0.8969\n",
            "Epoch 17/100\n",
            "474/474 - 5s - loss: 0.2609 - accuracy: 0.9071 - val_loss: 0.2797 - val_accuracy: 0.9014\n",
            "Epoch 18/100\n",
            "474/474 - 5s - loss: 0.2454 - accuracy: 0.9131 - val_loss: 0.2744 - val_accuracy: 0.9067\n",
            "Epoch 19/100\n",
            "474/474 - 5s - loss: 0.2325 - accuracy: 0.9183 - val_loss: 0.2646 - val_accuracy: 0.9103\n",
            "Epoch 20/100\n",
            "474/474 - 5s - loss: 0.2280 - accuracy: 0.9192 - val_loss: 0.2582 - val_accuracy: 0.9132\n",
            "Epoch 21/100\n",
            "474/474 - 5s - loss: 0.2172 - accuracy: 0.9227 - val_loss: 0.2589 - val_accuracy: 0.9136\n",
            "Epoch 22/100\n",
            "474/474 - 5s - loss: 0.2131 - accuracy: 0.9235 - val_loss: 0.2436 - val_accuracy: 0.9190\n",
            "Epoch 23/100\n",
            "474/474 - 5s - loss: 0.2023 - accuracy: 0.9286 - val_loss: 0.2430 - val_accuracy: 0.9211\n",
            "Epoch 24/100\n",
            "474/474 - 5s - loss: 0.1918 - accuracy: 0.9324 - val_loss: 0.2384 - val_accuracy: 0.9230\n",
            "Epoch 25/100\n",
            "474/474 - 5s - loss: 0.1872 - accuracy: 0.9332 - val_loss: 0.2366 - val_accuracy: 0.9228\n",
            "Epoch 26/100\n",
            "474/474 - 5s - loss: 0.1825 - accuracy: 0.9347 - val_loss: 0.2411 - val_accuracy: 0.9244\n",
            "Epoch 27/100\n",
            "474/474 - 5s - loss: 0.1780 - accuracy: 0.9376 - val_loss: 0.2350 - val_accuracy: 0.9244\n",
            "Epoch 28/100\n",
            "474/474 - 5s - loss: 0.1746 - accuracy: 0.9382 - val_loss: 0.2229 - val_accuracy: 0.9287\n",
            "Epoch 29/100\n",
            "474/474 - 5s - loss: 0.1638 - accuracy: 0.9418 - val_loss: 0.2260 - val_accuracy: 0.9283\n",
            "Epoch 30/100\n",
            "474/474 - 5s - loss: 0.1589 - accuracy: 0.9442 - val_loss: 0.2188 - val_accuracy: 0.9326\n",
            "Epoch 31/100\n",
            "474/474 - 5s - loss: 0.1531 - accuracy: 0.9463 - val_loss: 0.2158 - val_accuracy: 0.9324\n",
            "Epoch 32/100\n",
            "474/474 - 5s - loss: 0.1502 - accuracy: 0.9465 - val_loss: 0.2130 - val_accuracy: 0.9349\n",
            "Epoch 33/100\n",
            "474/474 - 5s - loss: 0.1481 - accuracy: 0.9479 - val_loss: 0.2151 - val_accuracy: 0.9364\n",
            "Epoch 34/100\n",
            "474/474 - 5s - loss: 0.1404 - accuracy: 0.9508 - val_loss: 0.2154 - val_accuracy: 0.9360\n",
            "Epoch 35/100\n",
            "474/474 - 5s - loss: 0.1398 - accuracy: 0.9517 - val_loss: 0.2078 - val_accuracy: 0.9379\n",
            "Epoch 36/100\n",
            "474/474 - 5s - loss: 0.1358 - accuracy: 0.9528 - val_loss: 0.2165 - val_accuracy: 0.9350\n",
            "Epoch 37/100\n",
            "474/474 - 5s - loss: 0.1314 - accuracy: 0.9542 - val_loss: 0.2017 - val_accuracy: 0.9410\n",
            "Epoch 38/100\n",
            "474/474 - 5s - loss: 0.1256 - accuracy: 0.9562 - val_loss: 0.2072 - val_accuracy: 0.9414\n",
            "Epoch 39/100\n",
            "474/474 - 5s - loss: 0.1263 - accuracy: 0.9556 - val_loss: 0.1971 - val_accuracy: 0.9441\n",
            "Epoch 40/100\n",
            "474/474 - 5s - loss: 0.1185 - accuracy: 0.9587 - val_loss: 0.2053 - val_accuracy: 0.9413\n",
            "Epoch 41/100\n",
            "474/474 - 5s - loss: 0.1176 - accuracy: 0.9597 - val_loss: 0.1993 - val_accuracy: 0.9452\n",
            "Epoch 42/100\n",
            "474/474 - 5s - loss: 0.1173 - accuracy: 0.9599 - val_loss: 0.2026 - val_accuracy: 0.9451\n",
            "Epoch 43/100\n",
            "474/474 - 5s - loss: 0.1143 - accuracy: 0.9600 - val_loss: 0.1989 - val_accuracy: 0.9451\n",
            "Epoch 44/100\n",
            "474/474 - 5s - loss: 0.1094 - accuracy: 0.9610 - val_loss: 0.2090 - val_accuracy: 0.9424\n",
            "Epoch 45/100\n",
            "474/474 - 5s - loss: 0.1079 - accuracy: 0.9623 - val_loss: 0.1951 - val_accuracy: 0.9501\n",
            "Epoch 46/100\n",
            "474/474 - 5s - loss: 0.1070 - accuracy: 0.9632 - val_loss: 0.1923 - val_accuracy: 0.9483\n",
            "Epoch 47/100\n",
            "474/474 - 5s - loss: 0.1057 - accuracy: 0.9624 - val_loss: 0.2014 - val_accuracy: 0.9480\n",
            "Epoch 48/100\n",
            "474/474 - 5s - loss: 0.0987 - accuracy: 0.9658 - val_loss: 0.1968 - val_accuracy: 0.9502\n",
            "Epoch 49/100\n",
            "474/474 - 5s - loss: 0.0970 - accuracy: 0.9660 - val_loss: 0.1960 - val_accuracy: 0.9471\n",
            "Epoch 50/100\n",
            "474/474 - 5s - loss: 0.0971 - accuracy: 0.9659 - val_loss: 0.1976 - val_accuracy: 0.9490\n",
            "Epoch 51/100\n",
            "474/474 - 5s - loss: 0.0955 - accuracy: 0.9670 - val_loss: 0.2006 - val_accuracy: 0.9490\n",
            "Epoch 52/100\n",
            "474/474 - 5s - loss: 0.0970 - accuracy: 0.9655 - val_loss: 0.1940 - val_accuracy: 0.9521\n",
            "Epoch 53/100\n",
            "474/474 - 5s - loss: 0.0924 - accuracy: 0.9683 - val_loss: 0.1904 - val_accuracy: 0.9508\n",
            "Epoch 54/100\n",
            "474/474 - 5s - loss: 0.0869 - accuracy: 0.9696 - val_loss: 0.1921 - val_accuracy: 0.9510\n",
            "Epoch 55/100\n",
            "474/474 - 5s - loss: 0.0887 - accuracy: 0.9695 - val_loss: 0.1930 - val_accuracy: 0.9524\n",
            "Epoch 56/100\n",
            "474/474 - 5s - loss: 0.0868 - accuracy: 0.9699 - val_loss: 0.1904 - val_accuracy: 0.9532\n",
            "Epoch 57/100\n",
            "474/474 - 5s - loss: 0.0882 - accuracy: 0.9695 - val_loss: 0.1947 - val_accuracy: 0.9532\n",
            "Epoch 58/100\n",
            "474/474 - 5s - loss: 0.0809 - accuracy: 0.9713 - val_loss: 0.2072 - val_accuracy: 0.9501\n",
            "Epoch 59/100\n",
            "474/474 - 5s - loss: 0.0860 - accuracy: 0.9697 - val_loss: 0.2010 - val_accuracy: 0.9523\n",
            "Epoch 60/100\n",
            "474/474 - 5s - loss: 0.0848 - accuracy: 0.9707 - val_loss: 0.1939 - val_accuracy: 0.9529\n",
            "Epoch 61/100\n",
            "474/474 - 5s - loss: 0.0807 - accuracy: 0.9715 - val_loss: 0.1937 - val_accuracy: 0.9521\n",
            "Epoch 62/100\n",
            "474/474 - 5s - loss: 0.0752 - accuracy: 0.9737 - val_loss: 0.1981 - val_accuracy: 0.9542\n",
            "Epoch 63/100\n",
            "474/474 - 5s - loss: 0.0740 - accuracy: 0.9745 - val_loss: 0.1989 - val_accuracy: 0.9537\n",
            "Epoch 64/100\n",
            "474/474 - 5s - loss: 0.0767 - accuracy: 0.9733 - val_loss: 0.1900 - val_accuracy: 0.9544\n",
            "Epoch 65/100\n",
            "474/474 - 5s - loss: 0.0745 - accuracy: 0.9740 - val_loss: 0.1937 - val_accuracy: 0.9527\n",
            "Epoch 66/100\n",
            "474/474 - 5s - loss: 0.0744 - accuracy: 0.9740 - val_loss: 0.2037 - val_accuracy: 0.9544\n",
            "Epoch 67/100\n",
            "474/474 - 5s - loss: 0.0758 - accuracy: 0.9738 - val_loss: 0.1921 - val_accuracy: 0.9550\n",
            "Epoch 68/100\n",
            "474/474 - 6s - loss: 0.0711 - accuracy: 0.9749 - val_loss: 0.1887 - val_accuracy: 0.9577\n",
            "Epoch 69/100\n",
            "474/474 - 5s - loss: 0.0704 - accuracy: 0.9761 - val_loss: 0.1942 - val_accuracy: 0.9556\n",
            "Epoch 70/100\n",
            "474/474 - 5s - loss: 0.0711 - accuracy: 0.9752 - val_loss: 0.2029 - val_accuracy: 0.9544\n",
            "Epoch 71/100\n",
            "474/474 - 5s - loss: 0.0668 - accuracy: 0.9761 - val_loss: 0.1889 - val_accuracy: 0.9578\n",
            "Epoch 72/100\n",
            "474/474 - 5s - loss: 0.0663 - accuracy: 0.9767 - val_loss: 0.2038 - val_accuracy: 0.9565\n",
            "Epoch 73/100\n",
            "474/474 - 5s - loss: 0.0664 - accuracy: 0.9774 - val_loss: 0.1924 - val_accuracy: 0.9567\n",
            "Epoch 74/100\n",
            "474/474 - 5s - loss: 0.0697 - accuracy: 0.9761 - val_loss: 0.1952 - val_accuracy: 0.9573\n",
            "Epoch 75/100\n",
            "474/474 - 5s - loss: 0.0621 - accuracy: 0.9792 - val_loss: 0.2053 - val_accuracy: 0.9575\n",
            "Epoch 76/100\n",
            "474/474 - 5s - loss: 0.0637 - accuracy: 0.9777 - val_loss: 0.1967 - val_accuracy: 0.9578\n",
            "Epoch 77/100\n",
            "474/474 - 5s - loss: 0.0591 - accuracy: 0.9796 - val_loss: 0.1963 - val_accuracy: 0.9575\n",
            "Epoch 78/100\n",
            "474/474 - 5s - loss: 0.0633 - accuracy: 0.9786 - val_loss: 0.1982 - val_accuracy: 0.9581\n",
            "Epoch 79/100\n",
            "474/474 - 5s - loss: 0.0602 - accuracy: 0.9790 - val_loss: 0.1968 - val_accuracy: 0.9583\n",
            "Epoch 80/100\n",
            "474/474 - 5s - loss: 0.0594 - accuracy: 0.9791 - val_loss: 0.1985 - val_accuracy: 0.9571\n",
            "Epoch 81/100\n",
            "474/474 - 5s - loss: 0.0595 - accuracy: 0.9796 - val_loss: 0.1941 - val_accuracy: 0.9586\n",
            "Epoch 82/100\n",
            "474/474 - 5s - loss: 0.0594 - accuracy: 0.9791 - val_loss: 0.2013 - val_accuracy: 0.9569\n",
            "Epoch 83/100\n",
            "474/474 - 5s - loss: 0.0578 - accuracy: 0.9800 - val_loss: 0.2110 - val_accuracy: 0.9572\n",
            "Epoch 84/100\n",
            "474/474 - 5s - loss: 0.0589 - accuracy: 0.9792 - val_loss: 0.2023 - val_accuracy: 0.9588\n",
            "Epoch 85/100\n",
            "474/474 - 5s - loss: 0.0578 - accuracy: 0.9801 - val_loss: 0.1993 - val_accuracy: 0.9591\n",
            "Epoch 86/100\n",
            "474/474 - 5s - loss: 0.0575 - accuracy: 0.9799 - val_loss: 0.2021 - val_accuracy: 0.9594\n",
            "Epoch 87/100\n",
            "474/474 - 5s - loss: 0.0574 - accuracy: 0.9802 - val_loss: 0.2030 - val_accuracy: 0.9577\n",
            "Epoch 88/100\n",
            "474/474 - 5s - loss: 0.0552 - accuracy: 0.9804 - val_loss: 0.2041 - val_accuracy: 0.9573\n",
            "Epoch 89/100\n",
            "474/474 - 5s - loss: 0.0568 - accuracy: 0.9807 - val_loss: 0.2031 - val_accuracy: 0.9585\n",
            "Epoch 90/100\n",
            "474/474 - 5s - loss: 0.0548 - accuracy: 0.9811 - val_loss: 0.2026 - val_accuracy: 0.9585\n",
            "Epoch 91/100\n",
            "474/474 - 5s - loss: 0.0535 - accuracy: 0.9812 - val_loss: 0.2038 - val_accuracy: 0.9593\n",
            "Epoch 92/100\n",
            "474/474 - 5s - loss: 0.0514 - accuracy: 0.9822 - val_loss: 0.2012 - val_accuracy: 0.9599\n",
            "Epoch 93/100\n",
            "474/474 - 5s - loss: 0.0545 - accuracy: 0.9815 - val_loss: 0.2031 - val_accuracy: 0.9567\n",
            "Epoch 94/100\n",
            "474/474 - 5s - loss: 0.0513 - accuracy: 0.9825 - val_loss: 0.2088 - val_accuracy: 0.9582\n",
            "Epoch 95/100\n",
            "474/474 - 5s - loss: 0.0512 - accuracy: 0.9819 - val_loss: 0.2104 - val_accuracy: 0.9596\n",
            "Epoch 96/100\n",
            "474/474 - 5s - loss: 0.0538 - accuracy: 0.9815 - val_loss: 0.2050 - val_accuracy: 0.9598\n",
            "Epoch 97/100\n",
            "474/474 - 5s - loss: 0.0503 - accuracy: 0.9828 - val_loss: 0.2018 - val_accuracy: 0.9600\n",
            "Epoch 98/100\n",
            "474/474 - 5s - loss: 0.0528 - accuracy: 0.9818 - val_loss: 0.1983 - val_accuracy: 0.9602\n",
            "Epoch 99/100\n",
            "474/474 - 5s - loss: 0.0487 - accuracy: 0.9833 - val_loss: 0.2069 - val_accuracy: 0.9600\n",
            "Epoch 100/100\n",
            "474/474 - 5s - loss: 0.0489 - accuracy: 0.9831 - val_loss: 0.2103 - val_accuracy: 0.9589\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-b07224158454>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m                         verbose = 2)\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m#model.save(newpath + r'\\fold-' + str(fold_no) + '.hdf5')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1377\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TraceContext'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1379\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1380\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}