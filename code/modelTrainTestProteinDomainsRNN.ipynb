{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "modelTrainTestProteinDomainsRNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oGiut-5Yl5j"
      },
      "source": [
        "import time\n",
        "import csv\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import tensorflow.keras.backend as K\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gGWAJT3SBBy"
      },
      "source": [
        "#\"\"\" Loading, padding and one-hot encoding of the data\"\"\"\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/dbosnacki/HelisDeepLearningCourse/main/cath-domain-description-file-v2_4ProcessedForNN.tsv' \n",
        "df = pd.read_csv(url, delimiter = \"\\t\", header=None)\n",
        "npd = df[3].to_numpy()\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5sFWxVtYqHs",
        "outputId": "6be075b1-5b38-4db3-9a62-864c363ad80a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "# find the maximal sequence length\n",
        "maxSeqLength = 0\n",
        "for sequence in npd:\n",
        "    l = len(sequence)\n",
        "    if l > maxSeqLength:\n",
        "      maxSeqLength = l \n",
        "\n",
        "data = list()\n",
        "for i in range(len(npd)):\n",
        "  alph_as_num = np.array(list(npd[i])).view(np.int32)\n",
        "  data.append(np.array(list(npd[i])).view(np.int32))\n",
        "\n",
        "#print(len(data))\n",
        "#print(data[1330])\n",
        "\n",
        "padded_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    data, padding=\"post\"\n",
        ")\n",
        "#print(padded_inputs)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "70\n",
            "94785\n",
            "[[84 68 68 ...  0  0  0]\n",
            " [65 69 81 ...  0  0  0]\n",
            " [80 69 81 ...  0  0  0]\n",
            " ...\n",
            " [87 71 75 ...  0  0  0]\n",
            " [86 71 83 ... 68 73 81]\n",
            " [75 76 86 ...  0  0  0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xw9BbM_KWUe5",
        "outputId": "5f078276-859c-425c-b140-28b4186eb77b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# padd the sequences with spaces to get equal length\n",
        "# dataset = []\n",
        "\n",
        "# for sequence in sequences:\n",
        "#     dataset.append(list(sequence.ljust(maxSeqLength, ' ')))\n",
        "    \n",
        "# #one hot encoding of the data\n",
        "# cat = OneHotEncoder()\n",
        "# dataset = cat.fit_transform(dataset).toarray()\n",
        "\n",
        "labels = list(df[2])    \n",
        "\n",
        "X = padded_inputs\n",
        "y = np.array(labels)\n",
        "\n",
        "print(X.shape)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "accuracy_per_fold = []\n",
        "loss_per_fold = []\n",
        "\n",
        "fold_no = 1\n",
        "seed = 10\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
        "\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(94785, 70)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvvZYrjKSSs8",
        "outputId": "42ab8790-4c5a-472d-edad-34871b11d4a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "for train_index, val_index in skf.split(X_train, y_train):\n",
        "    \n",
        "    print('Fold: ' + str(fold_no))\n",
        "    \n",
        "\n",
        "    # Define RNN model \n",
        "    model = keras.Sequential(\n",
        "        [\n",
        "           layers.Embedding(128, 16),\n",
        "           layers.LSTM(128, activation=\"relu\", name=\"rnn1\"),\n",
        "           #layers.Dense(64, activation=\"relu\", name=\"layer2\"),\n",
        "           layers.Dense(3, activation=\"softmax\", name=\"output\"),\n",
        "        ]\n",
        "    )\n",
        "    \n",
        "    # model.summary()\n",
        "\n",
        "    model.compile(\n",
        "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "        metrics=['accuracy'],\n",
        "        optimizer='adam',\n",
        "    )\n",
        "    \n",
        "\n",
        "    history = model.fit(X_train[train_index], \n",
        "                        y_train[train_index], \n",
        "                        batch_size = 1024, \n",
        "                        epochs = 20, \n",
        "                        #class_weight = class_weight, \n",
        "                        validation_data = (X_train[val_index], y_train[val_index]),\n",
        "                        #callbacks = callbacks_list,\n",
        "                        verbose = 2)\n",
        "    \n",
        "    scores = model.evaluate(X_test, y_test, verbose=2)\n",
        "    \n",
        "    #model.save(newpath + r'\\fold-' + str(fold_no) + '.hdf5') \n",
        "\n",
        "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "    accuracy_per_fold.append(scores[1] * 100)\n",
        "    loss_per_fold.append(scores[0])\n",
        "\n",
        "    # Increase fold number\n",
        "    fold_no = fold_no + 1\n",
        "\n",
        "# Average scores\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(len(accuracy_per_fold)):\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {accuracy_per_fold[i]}%')\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Average scores for all folds:')\n",
        "print(f'> Accuracy: {np.mean(accuracy_per_fold)} (+- {np.std(accuracy_per_fold)})')\n",
        "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "print('------------------------------------------------------------------------')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold: 1\n",
            "Epoch 1/20\n",
            "60/60 - 67s - loss: 1.0101 - accuracy: 0.5449 - val_loss: 0.9852 - val_accuracy: 0.5493\n",
            "Epoch 2/20\n",
            "60/60 - 64s - loss: 1.0010 - accuracy: 0.5492 - val_loss: 1.0230 - val_accuracy: 0.5493\n",
            "Epoch 3/20\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}