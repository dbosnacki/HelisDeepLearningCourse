{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "modelTrainTestProteinDomains.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dbosnacki/HelisDeepLearningCourse/blob/main/code/modelTrainTestProteinDomainsRNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oGiut-5Yl5j",
        "outputId": "12efa83e-6fec-4ade-e4a7-9b85adbd6a56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import time\n",
        "import csv\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import tensorflow.keras.backend as K\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "#\"\"\" Loading, padding and one-hot encoding of the data\"\"\"\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/dbosnacki/HelisDeepLearningCourse/main/cath-domain-description-file-v2_4ProcessedForNN.tsv' \n",
        "df = pd.read_csv(url, delimiter = \"\\t\", header=None)\n",
        "\n",
        "# extract the sequences list from the data frame\n",
        "sequences = list(df[3])\n",
        "\n",
        "# find the maximal sequence length\n",
        "maxSeqLength = 0\n",
        "for sequence in sequences:\n",
        "    if len(sequence) > maxSeqLength:\n",
        "      maxSeqLength = len(sequence)            \n",
        "    \n",
        "# padd the sequences with spaces to get equal length\n",
        "dataset = []\n",
        "\n",
        "for sequence in sequences:\n",
        "    dataset.append(list(sequence.ljust(maxSeqLength, ' ')))\n",
        "    \n",
        "#one hot encoding of the data\n",
        "cat = OneHotEncoder()\n",
        "dataset = cat.fit_transform(dataset).toarray()\n",
        "\n",
        "labels = list(df[2])    \n",
        "\n",
        "X = dataset\n",
        "y = np.array(labels)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "accuracy_per_fold = []\n",
        "loss_per_fold = []\n",
        "\n",
        "fold_no = 1\n",
        "seed = 10\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
        "\n",
        "for train_index, val_index in skf.split(X_train, y_train):\n",
        "    \n",
        "    print('Fold: ' + str(fold_no))\n",
        "    \n",
        "\n",
        "    # Define Sequential model with 3 layers\n",
        "    model = keras.Sequential(\n",
        "        [\n",
        "           layers.Dense(128, input_shape = (len(X_train[0]), ), activation=\"relu\", name=\"layer1\"),\n",
        "           layers.Dense(64, activation=\"relu\", name=\"layer2\"),\n",
        "           layers.Dense(3, activation=\"sigmoid\", name=\"layer3\"),\n",
        "           #\n",
        "           # layers.Dense(1024, input_shape = (len(X_train[0]), ), activation=\"relu\", name=\"layer1\"),\n",
        "           # layers.Dense(256, activation=\"relu\", name=\"layer2\"),\n",
        "           # layers.Dense(64, activation=\"relu\", name=\"layer3\"),\n",
        "           # layers.Dense(4, activation=\"relu\", name=\"layer4\"),\n",
        "           # layers.Dense(3, activation=\"sigmoid\", name=\"layer5\"),\n",
        "           #\n",
        "           #layers.Dense(128, input_shape = (len(X_train[0]), ), activation=\"relu\", name=\"layer1\"),\n",
        "           #layers.Dense(64, activation=\"relu\", name=\"layer2\"),\n",
        "           #layers.Dense(32, activation=\"relu\", name=\"layer3\"),\n",
        "           #layers.Dense(16, activation=\"relu\", name=\"layer4\"),\n",
        "           #layers.Dense(8, activation=\"relu\", name=\"layer5\"),\n",
        "           #layers.Dense(3, activation=\"relu\", name=\"layer6\"),\n",
        "           #\n",
        "           #layers.Dense((32), input_shape = (len(X_train[0]), ), activation=\"relu\", name=\"layer1\"),\n",
        "           #layers.Dense(16, activation=\"relu\", name=\"layer2\"),\n",
        "           #layers.Dense(3, activation=\"sigmoid\", name=\"layer3\"),\n",
        "        ]\n",
        "    )\n",
        "    \n",
        "    # model.summary()\n",
        "\n",
        "    model.compile(\n",
        "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "        metrics=['accuracy'],\n",
        "        optimizer='adam',\n",
        "    )\n",
        "    \n",
        "\n",
        "    history = model.fit(X_train[train_index], \n",
        "                        y_train[train_index], \n",
        "                        batch_size = 1024, \n",
        "                        epochs = 20, \n",
        "                        #class_weight = class_weight, \n",
        "                        validation_data = (X_train[val_index], y_train[val_index]),\n",
        "                        #callbacks = callbacks_list,\n",
        "                        verbose = 2)\n",
        "    \n",
        "    scores = model.evaluate(X_test, y_test, verbose=2)\n",
        "    \n",
        "    #model.save(newpath + r'\\fold-' + str(fold_no) + '.hdf5') \n",
        "\n",
        "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "    accuracy_per_fold.append(scores[1] * 100)\n",
        "    loss_per_fold.append(scores[0])\n",
        "\n",
        "    # Increase fold number\n",
        "    fold_no = fold_no + 1\n",
        "\n",
        "# Average scores\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(len(accuracy_per_fold)):\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {accuracy_per_fold[i]}%')\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Average scores for all folds:')\n",
        "print(f'> Accuracy: {np.mean(accuracy_per_fold)} (+- {np.std(accuracy_per_fold)})')\n",
        "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "print('------------------------------------------------------------------------')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold: 1\n",
            "Epoch 1/20\n",
            "60/60 - 2s - loss: 0.8048 - accuracy: 0.6312 - val_loss: 0.5848 - val_accuracy: 0.7616\n",
            "Epoch 2/20\n",
            "60/60 - 2s - loss: 0.4606 - accuracy: 0.8250 - val_loss: 0.3927 - val_accuracy: 0.8586\n",
            "Epoch 3/20\n",
            "60/60 - 2s - loss: 0.2873 - accuracy: 0.9012 - val_loss: 0.2839 - val_accuracy: 0.9066\n",
            "Epoch 4/20\n",
            "60/60 - 2s - loss: 0.1810 - accuracy: 0.9430 - val_loss: 0.2288 - val_accuracy: 0.9287\n",
            "Epoch 5/20\n",
            "60/60 - 2s - loss: 0.1168 - accuracy: 0.9650 - val_loss: 0.2139 - val_accuracy: 0.9365\n",
            "Epoch 6/20\n",
            "60/60 - 2s - loss: 0.0792 - accuracy: 0.9763 - val_loss: 0.1984 - val_accuracy: 0.9418\n",
            "Epoch 7/20\n",
            "60/60 - 2s - loss: 0.0593 - accuracy: 0.9823 - val_loss: 0.2038 - val_accuracy: 0.9442\n",
            "Epoch 8/20\n",
            "60/60 - 2s - loss: 0.0460 - accuracy: 0.9864 - val_loss: 0.2122 - val_accuracy: 0.9455\n",
            "Epoch 9/20\n",
            "60/60 - 2s - loss: 0.0383 - accuracy: 0.9881 - val_loss: 0.2126 - val_accuracy: 0.9484\n",
            "Epoch 10/20\n",
            "60/60 - 2s - loss: 0.0324 - accuracy: 0.9898 - val_loss: 0.2169 - val_accuracy: 0.9493\n",
            "Epoch 11/20\n",
            "60/60 - 2s - loss: 0.0276 - accuracy: 0.9910 - val_loss: 0.2246 - val_accuracy: 0.9512\n",
            "Epoch 12/20\n",
            "60/60 - 2s - loss: 0.0252 - accuracy: 0.9920 - val_loss: 0.2301 - val_accuracy: 0.9502\n",
            "Epoch 13/20\n",
            "60/60 - 2s - loss: 0.0222 - accuracy: 0.9930 - val_loss: 0.2373 - val_accuracy: 0.9505\n",
            "Epoch 14/20\n",
            "60/60 - 2s - loss: 0.0197 - accuracy: 0.9938 - val_loss: 0.2510 - val_accuracy: 0.9496\n",
            "Epoch 15/20\n",
            "60/60 - 2s - loss: 0.0173 - accuracy: 0.9946 - val_loss: 0.2486 - val_accuracy: 0.9515\n",
            "Epoch 16/20\n",
            "60/60 - 2s - loss: 0.0168 - accuracy: 0.9942 - val_loss: 0.2498 - val_accuracy: 0.9515\n",
            "Epoch 17/20\n",
            "60/60 - 2s - loss: 0.0148 - accuracy: 0.9951 - val_loss: 0.2568 - val_accuracy: 0.9526\n",
            "Epoch 18/20\n",
            "60/60 - 2s - loss: 0.0131 - accuracy: 0.9956 - val_loss: 0.2609 - val_accuracy: 0.9527\n",
            "Epoch 19/20\n",
            "60/60 - 2s - loss: 0.0127 - accuracy: 0.9959 - val_loss: 0.2740 - val_accuracy: 0.9523\n",
            "Epoch 20/20\n",
            "60/60 - 2s - loss: 0.0110 - accuracy: 0.9964 - val_loss: 0.2753 - val_accuracy: 0.9529\n",
            "593/593 - 1s - loss: 0.2962 - accuracy: 0.9500\n",
            "Score for fold 1: loss of 0.29615044593811035; accuracy of 94.99920606613159%\n",
            "Fold: 2\n",
            "Epoch 1/20\n",
            "60/60 - 2s - loss: 0.7742 - accuracy: 0.6508 - val_loss: 0.5503 - val_accuracy: 0.7825\n",
            "Epoch 2/20\n",
            "60/60 - 2s - loss: 0.4219 - accuracy: 0.8440 - val_loss: 0.3733 - val_accuracy: 0.8679\n",
            "Epoch 3/20\n",
            "60/60 - 2s - loss: 0.2536 - accuracy: 0.9162 - val_loss: 0.2715 - val_accuracy: 0.9097\n",
            "Epoch 4/20\n",
            "60/60 - 2s - loss: 0.1541 - accuracy: 0.9525 - val_loss: 0.2217 - val_accuracy: 0.9306\n",
            "Epoch 5/20\n",
            "60/60 - 2s - loss: 0.0961 - accuracy: 0.9712 - val_loss: 0.2073 - val_accuracy: 0.9378\n",
            "Epoch 6/20\n",
            "60/60 - 2s - loss: 0.0643 - accuracy: 0.9812 - val_loss: 0.2028 - val_accuracy: 0.9418\n",
            "Epoch 7/20\n",
            "60/60 - 2s - loss: 0.0476 - accuracy: 0.9860 - val_loss: 0.2092 - val_accuracy: 0.9445\n",
            "Epoch 8/20\n",
            "60/60 - 3s - loss: 0.0367 - accuracy: 0.9890 - val_loss: 0.2215 - val_accuracy: 0.9462\n",
            "Epoch 9/20\n",
            "60/60 - 2s - loss: 0.0304 - accuracy: 0.9909 - val_loss: 0.2229 - val_accuracy: 0.9451\n",
            "Epoch 10/20\n",
            "60/60 - 2s - loss: 0.0258 - accuracy: 0.9922 - val_loss: 0.2269 - val_accuracy: 0.9484\n",
            "Epoch 11/20\n",
            "60/60 - 2s - loss: 0.0219 - accuracy: 0.9937 - val_loss: 0.2384 - val_accuracy: 0.9480\n",
            "Epoch 12/20\n",
            "60/60 - 1s - loss: 0.0203 - accuracy: 0.9936 - val_loss: 0.2376 - val_accuracy: 0.9490\n",
            "Epoch 13/20\n",
            "60/60 - 2s - loss: 0.0172 - accuracy: 0.9951 - val_loss: 0.2495 - val_accuracy: 0.9461\n",
            "Epoch 14/20\n",
            "60/60 - 2s - loss: 0.0165 - accuracy: 0.9949 - val_loss: 0.2489 - val_accuracy: 0.9489\n",
            "Epoch 15/20\n",
            "60/60 - 2s - loss: 0.0158 - accuracy: 0.9948 - val_loss: 0.2540 - val_accuracy: 0.9466\n",
            "Epoch 16/20\n",
            "60/60 - 2s - loss: 0.0135 - accuracy: 0.9955 - val_loss: 0.2568 - val_accuracy: 0.9488\n",
            "Epoch 17/20\n",
            "60/60 - 2s - loss: 0.0119 - accuracy: 0.9961 - val_loss: 0.2688 - val_accuracy: 0.9481\n",
            "Epoch 18/20\n",
            "60/60 - 2s - loss: 0.0120 - accuracy: 0.9961 - val_loss: 0.2699 - val_accuracy: 0.9498\n",
            "Epoch 19/20\n",
            "60/60 - 1s - loss: 0.0107 - accuracy: 0.9964 - val_loss: 0.2720 - val_accuracy: 0.9509\n",
            "Epoch 20/20\n",
            "60/60 - 2s - loss: 0.0103 - accuracy: 0.9966 - val_loss: 0.2914 - val_accuracy: 0.9505\n",
            "593/593 - 1s - loss: 0.3064 - accuracy: 0.9492\n",
            "Score for fold 2: loss of 0.30637481808662415; accuracy of 94.92008090019226%\n",
            "Fold: 3\n",
            "Epoch 1/20\n",
            "60/60 - 2s - loss: 0.7734 - accuracy: 0.6525 - val_loss: 0.5513 - val_accuracy: 0.7790\n",
            "Epoch 2/20\n",
            "60/60 - 2s - loss: 0.4361 - accuracy: 0.8375 - val_loss: 0.3763 - val_accuracy: 0.8655\n",
            "Epoch 3/20\n",
            "60/60 - 2s - loss: 0.2717 - accuracy: 0.9090 - val_loss: 0.2754 - val_accuracy: 0.9091\n",
            "Epoch 4/20\n",
            "60/60 - 2s - loss: 0.1705 - accuracy: 0.9470 - val_loss: 0.2261 - val_accuracy: 0.9297\n",
            "Epoch 5/20\n",
            "60/60 - 2s - loss: 0.1098 - accuracy: 0.9673 - val_loss: 0.2034 - val_accuracy: 0.9382\n",
            "Epoch 6/20\n",
            "60/60 - 2s - loss: 0.0732 - accuracy: 0.9788 - val_loss: 0.1992 - val_accuracy: 0.9451\n",
            "Epoch 7/20\n",
            "60/60 - 2s - loss: 0.0526 - accuracy: 0.9845 - val_loss: 0.2035 - val_accuracy: 0.9455\n",
            "Epoch 8/20\n",
            "60/60 - 1s - loss: 0.0414 - accuracy: 0.9875 - val_loss: 0.2078 - val_accuracy: 0.9503\n",
            "Epoch 9/20\n",
            "60/60 - 2s - loss: 0.0324 - accuracy: 0.9902 - val_loss: 0.2117 - val_accuracy: 0.9521\n",
            "Epoch 10/20\n",
            "60/60 - 2s - loss: 0.0271 - accuracy: 0.9916 - val_loss: 0.2310 - val_accuracy: 0.9462\n",
            "Epoch 11/20\n",
            "60/60 - 1s - loss: 0.0272 - accuracy: 0.9910 - val_loss: 0.2255 - val_accuracy: 0.9517\n",
            "Epoch 12/20\n",
            "60/60 - 2s - loss: 0.0203 - accuracy: 0.9937 - val_loss: 0.2315 - val_accuracy: 0.9525\n",
            "Epoch 13/20\n",
            "60/60 - 2s - loss: 0.0190 - accuracy: 0.9938 - val_loss: 0.2334 - val_accuracy: 0.9527\n",
            "Epoch 14/20\n",
            "60/60 - 2s - loss: 0.0183 - accuracy: 0.9944 - val_loss: 0.2386 - val_accuracy: 0.9519\n",
            "Epoch 15/20\n",
            "60/60 - 2s - loss: 0.0165 - accuracy: 0.9948 - val_loss: 0.2470 - val_accuracy: 0.9530\n",
            "Epoch 16/20\n",
            "60/60 - 1s - loss: 0.0142 - accuracy: 0.9956 - val_loss: 0.2549 - val_accuracy: 0.9503\n",
            "Epoch 17/20\n",
            "60/60 - 2s - loss: 0.0128 - accuracy: 0.9955 - val_loss: 0.2568 - val_accuracy: 0.9529\n",
            "Epoch 18/20\n",
            "60/60 - 1s - loss: 0.0118 - accuracy: 0.9962 - val_loss: 0.2569 - val_accuracy: 0.9527\n",
            "Epoch 19/20\n",
            "60/60 - 2s - loss: 0.0111 - accuracy: 0.9962 - val_loss: 0.2602 - val_accuracy: 0.9540\n",
            "Epoch 20/20\n",
            "60/60 - 2s - loss: 0.0112 - accuracy: 0.9964 - val_loss: 0.2707 - val_accuracy: 0.9527\n",
            "593/593 - 1s - loss: 0.3048 - accuracy: 0.9489\n",
            "Score for fold 3: loss of 0.3048182427883148; accuracy of 94.88843083381653%\n",
            "Fold: 4\n",
            "Epoch 1/20\n",
            "60/60 - 2s - loss: 0.7820 - accuracy: 0.6460 - val_loss: 0.5503 - val_accuracy: 0.7786\n",
            "Epoch 2/20\n",
            "60/60 - 2s - loss: 0.4389 - accuracy: 0.8371 - val_loss: 0.3679 - val_accuracy: 0.8667\n",
            "Epoch 3/20\n",
            "60/60 - 2s - loss: 0.2689 - accuracy: 0.9087 - val_loss: 0.2689 - val_accuracy: 0.9080\n",
            "Epoch 4/20\n",
            "60/60 - 2s - loss: 0.1652 - accuracy: 0.9484 - val_loss: 0.2176 - val_accuracy: 0.9306\n",
            "Epoch 5/20\n",
            "60/60 - 1s - loss: 0.1033 - accuracy: 0.9698 - val_loss: 0.2086 - val_accuracy: 0.9360\n",
            "Epoch 6/20\n",
            "60/60 - 2s - loss: 0.0711 - accuracy: 0.9794 - val_loss: 0.1979 - val_accuracy: 0.9436\n",
            "Epoch 7/20\n",
            "60/60 - 2s - loss: 0.0499 - accuracy: 0.9856 - val_loss: 0.1967 - val_accuracy: 0.9474\n",
            "Epoch 8/20\n",
            "60/60 - 2s - loss: 0.0386 - accuracy: 0.9889 - val_loss: 0.2023 - val_accuracy: 0.9467\n",
            "Epoch 9/20\n",
            "60/60 - 2s - loss: 0.0309 - accuracy: 0.9906 - val_loss: 0.2078 - val_accuracy: 0.9494\n",
            "Epoch 10/20\n",
            "60/60 - 2s - loss: 0.0253 - accuracy: 0.9926 - val_loss: 0.2105 - val_accuracy: 0.9492\n",
            "Epoch 11/20\n",
            "60/60 - 1s - loss: 0.0221 - accuracy: 0.9931 - val_loss: 0.2159 - val_accuracy: 0.9510\n",
            "Epoch 12/20\n",
            "60/60 - 1s - loss: 0.0184 - accuracy: 0.9945 - val_loss: 0.2207 - val_accuracy: 0.9504\n",
            "Epoch 13/20\n",
            "60/60 - 2s - loss: 0.0159 - accuracy: 0.9955 - val_loss: 0.2282 - val_accuracy: 0.9519\n",
            "Epoch 14/20\n",
            "60/60 - 2s - loss: 0.0144 - accuracy: 0.9960 - val_loss: 0.2322 - val_accuracy: 0.9519\n",
            "Epoch 15/20\n",
            "60/60 - 2s - loss: 0.0134 - accuracy: 0.9960 - val_loss: 0.2357 - val_accuracy: 0.9513\n",
            "Epoch 16/20\n",
            "60/60 - 1s - loss: 0.0116 - accuracy: 0.9967 - val_loss: 0.2403 - val_accuracy: 0.9519\n",
            "Epoch 17/20\n",
            "60/60 - 2s - loss: 0.0111 - accuracy: 0.9965 - val_loss: 0.2452 - val_accuracy: 0.9521\n",
            "Epoch 18/20\n",
            "60/60 - 2s - loss: 0.0115 - accuracy: 0.9964 - val_loss: 0.2526 - val_accuracy: 0.9523\n",
            "Epoch 19/20\n",
            "60/60 - 2s - loss: 0.0103 - accuracy: 0.9965 - val_loss: 0.2617 - val_accuracy: 0.9521\n",
            "Epoch 20/20\n",
            "60/60 - 2s - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.2669 - val_accuracy: 0.9521\n",
            "593/593 - 1s - loss: 0.2944 - accuracy: 0.9493\n",
            "Score for fold 4: loss of 0.29441165924072266; accuracy of 94.9306309223175%\n",
            "Fold: 5\n",
            "Epoch 1/20\n",
            "60/60 - 2s - loss: 0.8019 - accuracy: 0.6350 - val_loss: 0.5834 - val_accuracy: 0.7615\n",
            "Epoch 2/20\n",
            "60/60 - 2s - loss: 0.4463 - accuracy: 0.8301 - val_loss: 0.3860 - val_accuracy: 0.8601\n",
            "Epoch 3/20\n",
            "60/60 - 2s - loss: 0.2607 - accuracy: 0.9115 - val_loss: 0.2732 - val_accuracy: 0.9093\n",
            "Epoch 4/20\n",
            "60/60 - 2s - loss: 0.1525 - accuracy: 0.9515 - val_loss: 0.2232 - val_accuracy: 0.9319\n",
            "Epoch 5/20\n",
            "60/60 - 2s - loss: 0.0937 - accuracy: 0.9706 - val_loss: 0.2197 - val_accuracy: 0.9329\n",
            "Epoch 6/20\n",
            "60/60 - 2s - loss: 0.0631 - accuracy: 0.9814 - val_loss: 0.2193 - val_accuracy: 0.9362\n",
            "Epoch 7/20\n",
            "60/60 - 2s - loss: 0.0462 - accuracy: 0.9863 - val_loss: 0.2193 - val_accuracy: 0.9444\n",
            "Epoch 8/20\n",
            "60/60 - 2s - loss: 0.0378 - accuracy: 0.9882 - val_loss: 0.2245 - val_accuracy: 0.9442\n",
            "Epoch 9/20\n",
            "60/60 - 2s - loss: 0.0312 - accuracy: 0.9906 - val_loss: 0.2334 - val_accuracy: 0.9468\n",
            "Epoch 10/20\n",
            "60/60 - 2s - loss: 0.0249 - accuracy: 0.9926 - val_loss: 0.2406 - val_accuracy: 0.9472\n",
            "Epoch 11/20\n",
            "60/60 - 2s - loss: 0.0221 - accuracy: 0.9934 - val_loss: 0.2514 - val_accuracy: 0.9463\n",
            "Epoch 12/20\n",
            "60/60 - 2s - loss: 0.0195 - accuracy: 0.9939 - val_loss: 0.2621 - val_accuracy: 0.9463\n",
            "Epoch 13/20\n",
            "60/60 - 2s - loss: 0.0178 - accuracy: 0.9946 - val_loss: 0.2579 - val_accuracy: 0.9484\n",
            "Epoch 14/20\n",
            "60/60 - 2s - loss: 0.0147 - accuracy: 0.9956 - val_loss: 0.2645 - val_accuracy: 0.9482\n",
            "Epoch 15/20\n",
            "60/60 - 2s - loss: 0.0136 - accuracy: 0.9957 - val_loss: 0.2773 - val_accuracy: 0.9474\n",
            "Epoch 16/20\n",
            "60/60 - 2s - loss: 0.0132 - accuracy: 0.9957 - val_loss: 0.2771 - val_accuracy: 0.9491\n",
            "Epoch 17/20\n",
            "60/60 - 2s - loss: 0.0107 - accuracy: 0.9967 - val_loss: 0.2824 - val_accuracy: 0.9488\n",
            "Epoch 18/20\n",
            "60/60 - 2s - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.2886 - val_accuracy: 0.9494\n",
            "Epoch 19/20\n",
            "60/60 - 2s - loss: 0.0093 - accuracy: 0.9971 - val_loss: 0.2916 - val_accuracy: 0.9478\n",
            "Epoch 20/20\n",
            "60/60 - 2s - loss: 0.0094 - accuracy: 0.9970 - val_loss: 0.2968 - val_accuracy: 0.9501\n",
            "593/593 - 1s - loss: 0.3067 - accuracy: 0.9503\n",
            "Score for fold 5: loss of 0.30668264627456665; accuracy of 95.02558708190918%\n",
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "------------------------------------------------------------------------\n",
            "> Fold 1 - Loss: 0.29615044593811035 - Accuracy: 94.99920606613159%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 2 - Loss: 0.30637481808662415 - Accuracy: 94.92008090019226%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 3 - Loss: 0.3048182427883148 - Accuracy: 94.88843083381653%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 4 - Loss: 0.29441165924072266 - Accuracy: 94.9306309223175%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 5 - Loss: 0.30668264627456665 - Accuracy: 95.02558708190918%\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> Accuracy: 94.95278716087341 (+- 0.051296936546199615)\n",
            "> Loss: 0.30168756246566775\n",
            "------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}