{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise2.ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyOAi/AUAYMS2LIJk6pjZ2OK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dbosnacki/HelisDeepLearningCourse/blob/main/exercises/Exercise2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCHnQxbU9RmZ"
      },
      "source": [
        "# Library Import\n",
        "Import various libraries and funcitons which will be used in the code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yxa-nYLWAidp"
      },
      "source": [
        "import time\n",
        "import csv\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import tensorflow.keras.backend as K\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4BKygUQ9e6Z"
      },
      "source": [
        "# Data import\n",
        "\n",
        "*   We use version 2.4 of the CATH database of protein structures https://www.cathdb.info/\n",
        "\n",
        "*  A preprocessed copy of the database from 'https://raw.githubusercontent.com/dbosnacki/HelisDeepLearningCourse/main/cath-domain-description-file-v2_4ProcessedForNN.tsv' \n",
        "as a tab separated text document\n",
        "*   You can import this kind of data files (CSV) with pandas or numpy\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWXFgDZGBD-M"
      },
      "source": [
        "\n",
        "url = 'https://raw.githubusercontent.com/dbosnacki/HelisDeepLearningCourse/main/cath-domain-description-file-v2_4ProcessedForNN.tsv' \n",
        "df = pd.read_csv(url, delimiter = \"\\t\", header=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eB4-v4dT9ghL"
      },
      "source": [
        "# Data preprocessing\n",
        "\n",
        "\n",
        "*   Extract from the data frame the second and third column which correspond to the labes and the sequences ofo the protein domains, respectively\n",
        "*   Pad the data with spaces up to the maximal length \n",
        "*   Encode the data using one-hot encoding\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40WEurEGBP8Y"
      },
      "source": [
        "# extract the sequences list from the data frame\n",
        "sequences = list(df[3])\n",
        "\n",
        "# find the maximal sequence length\n",
        "maxSeqLength = 0\n",
        "for sequence in sequences:\n",
        "    if len(sequence) > maxSeqLength:\n",
        "      maxSeqLength = len(sequence)            \n",
        "    \n",
        "# padd the sequences with spaces to get equal length\n",
        "dataset = []\n",
        "\n",
        "for sequence in sequences:\n",
        "    dataset.append(list(sequence.ljust(maxSeqLength, ' ')))\n",
        "    \n",
        "#one hot encoding of the data\n",
        "cat = OneHotEncoder()\n",
        "dataset = cat.fit_transform(dataset).toarray()\n",
        "\n",
        "labels = list(df[2])    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9T5_ACeFAQD-"
      },
      "source": [
        "# Building, training and evaulating the model\n",
        "\n",
        "\n",
        "*   Assign the data and labels to the corresponding variables\n",
        "*   Use cross validation to evaluate the results\n",
        "*   Build a deep neural network model to predict the protein domain class\n",
        "*   Train and test/evaluate the model at the end of each fold using some metric, e.g., accuracy\n",
        "*   Save the evaluation results for each folt in a list\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLCOSTpbQPS0"
      },
      "source": [
        "## Assign the data and the labels and split them into training and test/ealuation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_I0kgzDrQi43"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QMyu0a5Qx32"
      },
      "source": [
        "## Building the model\n",
        "\n",
        "\n",
        "*   Compose the model layer by layer\n",
        "*   Print a summary\n",
        "*   Compile the model\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "272-5ttTQ5QA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0OiFe0TQrOU"
      },
      "source": [
        "## Training\n",
        "Train the model using the training part of the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8Og1JEeR36C"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2X_LU55R7lI"
      },
      "source": [
        "## Evaluation\n",
        "Evaluta the model using the test part of the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mESNVUrSHgw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrsWslmzSiiO"
      },
      "source": [
        "## Cross-validation\n",
        "* Put together the building, training and evalution steps in a cross-validation loop\n",
        "* collect the mettric, e.g., accuracy, as well as the loss for each fold in a list or dictionary such that it can be processed later\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8ArZkJ-C9F5"
      },
      "source": [
        "...\n",
        "\n",
        "accuracy_per_fold = []\n",
        "loss_per_fold = []\n",
        "\n",
        "fold_no = 1\n",
        "seed = 10\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
        "\n",
        "for train_index, val_index in skf.split(X_train, y_train):\n",
        "    \n",
        "    print('Fold: ' + str(fold_no)) \n",
        "\n",
        "    ...\n",
        "\n",
        "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "    accuracy_per_fold.append(scores[1] * 100)\n",
        "    loss_per_fold.append(scores[0])\n",
        "\n",
        "    # Increase fold number\n",
        "    fold_no = fold_no + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIOJr10UDVx5"
      },
      "source": [
        "# Evaluation results\n",
        "* Print the saved evalutaion results for each of the fold as well as some statistics, like average or standard deviation\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaFouTHFDdH1"
      },
      "source": [
        "# Average scores\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(len(accuracy_per_fold)):\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {accuracy_per_fold[i]}%')\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Average scores for all folds:')\n",
        "print(f'> Accuracy: {np.mean(accuracy_per_fold)} (+- {np.std(accuracy_per_fold)})')\n",
        "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "print('------------------------------------------------------------------------')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}