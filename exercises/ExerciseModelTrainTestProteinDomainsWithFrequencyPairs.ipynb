{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ExerciseModelTrainTestProteinDomainsWithFrequencyPairs.ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyOtz+h0D/gOxovi/nXPgYqw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dbosnacki/HelisDeepLearningCourse/blob/main/exercises/ExerciseModelTrainTestProteinDomainsWithFrequencyPairs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCHnQxbU9RmZ"
      },
      "source": [
        "# Library Import\n",
        "Import various libraries and funcitons which will be used in the code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yxa-nYLWAidp"
      },
      "source": [
        "import time\n",
        "import csv\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import tensorflow.keras.backend as K\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4BKygUQ9e6Z"
      },
      "source": [
        "# Data import\n",
        "\n",
        "*   We use version 2.4 of the CATH database of protein structures https://www.cathdb.info/\n",
        "\n",
        "*  A preprocessed copy of the database from 'https://raw.githubusercontent.com/dbosnacki/HelisDeepLearningCourse/main/cath-domain-description-file-v2_4ProcessedForNN.tsv' \n",
        "as a tab separated text document\n",
        "*   You can import this kind of data files (CSV) with pandas or numpy\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWXFgDZGBD-M"
      },
      "source": [
        "#Loading, padding and one-hot encoding of the data\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/dbosnacki/HelisDeepLearningCourse/main/cath-domain-description-file-v2_4ProcessedForNN.tsv' \n",
        "df = pd.read_csv(url, delimiter = \"\\t\", header=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eB4-v4dT9ghL"
      },
      "source": [
        "# Data preprocessing\n",
        "\n",
        "\n",
        "*   Extract from the data frame the second and third column which correspond to the labes and the sequences ofo the protein domains, respectively\n",
        "*   Implement the occurrence frequency pair represntation of the sequences (you can use the Python funciton we provide or write your own) \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40WEurEGBP8Y"
      },
      "source": [
        "def makeSignature(dseqs, ordered = False):\n",
        "    \"\"\" Produce the letter pair occourrence signature of the (amino acid) sequence\"\"\"\n",
        "    \n",
        "    aminoAcids = ['A', 'R', 'N', 'D', 'C', 'Q', 'E', 'G', 'H', 'I', 'L',\\\n",
        "                  'K', 'M', 'F', 'P', 'S', 'T', 'W', 'Y', 'V']\n",
        "    signature = []\n",
        "        \n",
        "    if ordered:\n",
        "        for aa1 in aminoAcids:\n",
        "            for aa2 in aminoAcids:\n",
        "                signature.append(dseqs.count(aa1+aa2))\n",
        "    else:\n",
        "        for i in range(len(aminoAcids)):\n",
        "            for j in range(i+1):\n",
        "                if not (i == j): \n",
        "                    signature.append(dseqs.count(aminoAcids[i]+aminoAcids[j]) + dseqs.count(aminoAcids[j]+aminoAcids[i]))\n",
        "                else:\n",
        "                    signature.append(dseqs.count(aminoAcids[i]+aminoAcids[j]))\n",
        "    signature = np.array(signature)       \n",
        "    return signature\n",
        "\n",
        "\n",
        "# generate the signature (features) of the sequences based on pair frequencies\n",
        "sequences = list(df[3])\n",
        "\n",
        "# extract the sequences list from the data frame\n",
        "dataset = []          \n",
        "        \n",
        "for sequence in sequences:\n",
        "    dataset.append(makeSignature(sequence))\n",
        "\n",
        "#labels = pd.DataFrame(df).to_numpy()\n",
        "labels = list(df[2])   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9T5_ACeFAQD-"
      },
      "source": [
        "# Building, training and evaulating the model\n",
        "\n",
        "\n",
        "*   Assign the data and labels to the corresponding variables\n",
        "*   Use cross validation to evaluate the results\n",
        "*   Build a deep neural network model to predict the protein domain class\n",
        "*   Train and test/evaluate the model at the end of each fold using some metric, e.g., accuracy\n",
        "*   Save the evaluation results for each folt in a list\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLCOSTpbQPS0"
      },
      "source": [
        "## Assign the data and the labels and split them into training and test/ealuation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_I0kgzDrQi43"
      },
      "source": [
        "X = np.array(dataset)\n",
        "y = np.array(labels)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QMyu0a5Qx32"
      },
      "source": [
        "## Building the model\n",
        "\n",
        "\n",
        "*   Compose the model layer by layer\n",
        "*   Print a summary\n",
        "*   Compile the model\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "272-5ttTQ5QA"
      },
      "source": [
        "# Define Sequential model with 3 layers\n",
        "  model = keras.Sequential(\n",
        "        [\n",
        "           layers.Dense(128, input_shape = (len(X_train[0]), ), activation=\"relu\", name=\"layer1\"),\n",
        "           layers.Dense(64, activation=\"relu\", name=\"layer2\"),\n",
        "           layers.Dense(3, activation=\"sigmoid\", name=\"layer3\"),\n",
        "           #\n",
        "           # layers.Dense(1024, input_shape = (len(X_train[0]), ), activation=\"relu\", name=\"layer1\"),\n",
        "           # layers.Dense(256, activation=\"relu\", name=\"layer2\"),\n",
        "           # layers.Dense(64, activation=\"relu\", name=\"layer3\"),\n",
        "           # layers.Dense(4, activation=\"relu\", name=\"layer4\"),\n",
        "           # layers.Dense(3, activation=\"sigmoid\", name=\"layer5\"),\n",
        "           #\n",
        "           #layers.Dense(128, input_shape = (len(X_train[0]), ), activation=\"relu\", name=\"layer1\"),\n",
        "           #layers.Dense(64, activation=\"relu\", name=\"layer2\"),\n",
        "           #layers.Dense(32, activation=\"relu\", name=\"layer3\"),\n",
        "           #layers.Dense(16, activation=\"relu\", name=\"layer4\"),\n",
        "           #layers.Dense(8, activation=\"relu\", name=\"layer5\"),\n",
        "           #layers.Dense(3, activation=\"relu\", name=\"layer6\"),\n",
        "           #\n",
        "           #layers.Dense((32), input_shape = (len(X_train[0]), ), activation=\"relu\", name=\"layer1\"),\n",
        "           #layers.Dense(16, activation=\"relu\", name=\"layer2\"),\n",
        "           #layers.Dense(3, activation=\"sigmoid\", name=\"layer3\"),\n",
        "        ]\n",
        "    )\n",
        "    \n",
        "model.summary()\n",
        "\n",
        "model.compile(\n",
        "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "        metrics=['accuracy'],\n",
        "        optimizer='adam',\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0OiFe0TQrOU"
      },
      "source": [
        "## Training\n",
        "Train the model using the training part of the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8Og1JEeR36C"
      },
      "source": [
        "history = model.fit(X_train[train_index], \n",
        "                        y_train[train_index], \n",
        "                        batch_size = 1024, \n",
        "                        epochs = 20, \n",
        "                        #class_weight = class_weight, \n",
        "                        validation_data = (X_train[val_index], y_train[val_index]),\n",
        "                        #callbacks = callbacks_list,\n",
        "                        verbose = 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2X_LU55R7lI"
      },
      "source": [
        "## Evaluation\n",
        "Evaluta the model using the test part of the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mESNVUrSHgw"
      },
      "source": [
        "scores = model.evaluate(X_test, y_test, verbose=2)\n",
        "#model.save(newpath + r'\\fold-' + str(fold_no) + '.hdf5') \n",
        "print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrsWslmzSiiO"
      },
      "source": [
        "## Cross-validation\n",
        "* Put together the building, training and evalution steps in a cross-validation loop\n",
        "* collect the mettric, e.g., accuracy, as well as the loss for each fold in a list or dictionary such that it can be processed later\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8ArZkJ-C9F5"
      },
      "source": [
        "X = dataset\n",
        "y = np.array(labels)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "accuracy_per_fold = []\n",
        "loss_per_fold = []\n",
        "\n",
        "fold_no = 1\n",
        "seed = 10\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
        "\n",
        "for train_index, val_index in skf.split(X_train, y_train):\n",
        "    \n",
        "    print('Fold: ' + str(fold_no))\n",
        "    \n",
        "\n",
        "    # Define Sequential model with 3 layers\n",
        "    model = keras.Sequential(\n",
        "        [\n",
        "           layers.Dense(128, input_shape = (len(X_train[0]), ), activation=\"relu\", name=\"layer1\"),\n",
        "           layers.Dense(64, activation=\"relu\", name=\"layer2\"),\n",
        "           layers.Dense(3, activation=\"sigmoid\", name=\"layer3\"),\n",
        "           #\n",
        "           # layers.Dense(1024, input_shape = (len(X_train[0]), ), activation=\"relu\", name=\"layer1\"),\n",
        "           # layers.Dense(256, activation=\"relu\", name=\"layer2\"),\n",
        "           # layers.Dense(64, activation=\"relu\", name=\"layer3\"),\n",
        "           # layers.Dense(4, activation=\"relu\", name=\"layer4\"),\n",
        "           # layers.Dense(3, activation=\"sigmoid\", name=\"layer5\"),\n",
        "           #\n",
        "           #layers.Dense(128, input_shape = (len(X_train[0]), ), activation=\"relu\", name=\"layer1\"),\n",
        "           #layers.Dense(64, activation=\"relu\", name=\"layer2\"),\n",
        "           #layers.Dense(32, activation=\"relu\", name=\"layer3\"),\n",
        "           #layers.Dense(16, activation=\"relu\", name=\"layer4\"),\n",
        "           #layers.Dense(8, activation=\"relu\", name=\"layer5\"),\n",
        "           #layers.Dense(3, activation=\"relu\", name=\"layer6\"),\n",
        "           #\n",
        "           #layers.Dense((32), input_shape = (len(X_train[0]), ), activation=\"relu\", name=\"layer1\"),\n",
        "           #layers.Dense(16, activation=\"relu\", name=\"layer2\"),\n",
        "           #layers.Dense(3, activation=\"sigmoid\", name=\"layer3\"),\n",
        "        ]\n",
        "    )\n",
        "    \n",
        "    model.summary()\n",
        "    model.compile(\n",
        "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "        metrics=['accuracy'],\n",
        "        optimizer='adam',\n",
        "    )\n",
        "    \n",
        "\n",
        "    history = model.fit(X_train[train_index], \n",
        "                        y_train[train_index], \n",
        "                        batch_size = 1024, \n",
        "                        epochs = 20, \n",
        "                        #class_weight = class_weight, \n",
        "                        validation_data = (X_train[val_index], y_train[val_index]),\n",
        "                        #callbacks = callbacks_list,\n",
        "                        verbose = 2)\n",
        "    \n",
        "    scores = model.evaluate(X_test, y_test, verbose=2)\n",
        "    \n",
        "    #model.save(newpath + r'\\fold-' + str(fold_no) + '.hdf5') \n",
        "\n",
        "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "    accuracy_per_fold.append(scores[1] * 100)\n",
        "    loss_per_fold.append(scores[0])\n",
        "\n",
        "    # Increase fold number\n",
        "    fold_no = fold_no + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIOJr10UDVx5"
      },
      "source": [
        "# Evaluation results\n",
        "* Print the saved evalutaion results for each of the fold as well as some statistics, like average or standard deviation\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaFouTHFDdH1"
      },
      "source": [
        "# Average scores\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(len(accuracy_per_fold)):\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {accuracy_per_fold[i]}%')\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Average scores for all folds:')\n",
        "print(f'> Accuracy: {np.mean(accuracy_per_fold)} (+- {np.std(accuracy_per_fold)})')\n",
        "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "print('------------------------------------------------------------------------')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}