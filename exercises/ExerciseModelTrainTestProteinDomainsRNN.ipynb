{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ExerciseModelTrainTestProteinDomainsRNN.ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyOA9S8zIPsQ0jNGyF7kvShU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dbosnacki/HelisDeepLearningCourse/blob/main/exercises/ExerciseModelTrainTestProteinDomainsRNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCHnQxbU9RmZ"
      },
      "source": [
        "# Library Import\n",
        "Import various libraries and funcitons which will be used in the code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yxa-nYLWAidp"
      },
      "source": [
        "import time\n",
        "import csv\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import tensorflow.keras.backend as K\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4BKygUQ9e6Z"
      },
      "source": [
        "# Data import\n",
        "\n",
        "*   We use version 2.4 of the CATH database of protein structures https://www.cathdb.info/\n",
        "\n",
        "*  A preprocessed copy of the database from 'https://raw.githubusercontent.com/dbosnacki/HelisDeepLearningCourse/main/cath-domain-description-file-v2_4ProcessedForNN.tsv' \n",
        "as a tab separated text document\n",
        "*   You can import this kind of data files (CSV) with pandas or numpy\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWXFgDZGBD-M"
      },
      "source": [
        "#Loading, padding and one-hot encoding of the data\n",
        "url = 'https://raw.githubusercontent.com/dbosnacki/HelisDeepLearningCourse/main/cath-domain-description-file-v2_4ProcessedForNN.tsv' \n",
        "df = pd.read_csv(url, delimiter = \"\\t\", header=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eB4-v4dT9ghL"
      },
      "source": [
        "# Data preprocessing\n",
        "\n",
        "\n",
        "*   Extract from the data frame the second and third column which correspond to the labes and the sequences ofo the protein domains, respectively\n",
        "*   Pad the sequences up to some maximal length\n",
        "*   Implement one-hot encoding of the sequences\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40WEurEGBP8Y"
      },
      "source": [
        "# generate the signature (features) of the sequences based on pair frequencies\n",
        "npd = df[3].to_numpy()\n",
        "\n",
        "# extract the sequences list from the data frame\n",
        "dataset = []          \n",
        "        \n",
        "maxSeqLength = 0\n",
        "for sequence in npd:\n",
        "    l = len(sequence)\n",
        "    if l > maxSeqLength:\n",
        "      maxSeqLength = l \n",
        "\n",
        "data = list()\n",
        "for i in range(len(npd)):\n",
        "  alph_as_num = np.array(list(npd[i])).view(np.int32)\n",
        "  data.append(np.array(list(npd[i])).view(np.int32))\n",
        "\n",
        "padded_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    data, padding=\"post\"\n",
        ")\n",
        "#print(padded_inputs)\n",
        "\n",
        "#labels = pd.DataFrame(df).to_numpy()\n",
        "labels = list(df[2])   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9T5_ACeFAQD-"
      },
      "source": [
        "# Building, training and evaulating the model\n",
        "\n",
        "\n",
        "*   Assign the data and labels to the corresponding variables\n",
        "*   Use cross validation to evaluate the results\n",
        "*   Build a deep neural network model to predict the protein domain class\n",
        "*   Train and test/evaluate the model at the end of each fold using some metric, e.g., accuracy\n",
        "*   Save the evaluation results for each folt in a list\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLCOSTpbQPS0"
      },
      "source": [
        "## Assign the data and the labels and split them into training and test/ealuation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_I0kgzDrQi43"
      },
      "source": [
        "X = padded_inputs\n",
        "y = np.array(labels)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QMyu0a5Qx32"
      },
      "source": [
        "## Building the model\n",
        "\n",
        "\n",
        "*   Compose the model layer by layer\n",
        "*   Print a summary\n",
        "*   Compile the model\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "272-5ttTQ5QA"
      },
      "source": [
        "# Define RNN model \n",
        "model = keras.Sequential(\n",
        "        [\n",
        "           layers.Embedding(128, 64),\n",
        "           layers.Bidirectional(layers.LSTM(128, dropout = 0.4, name=\"rnn1\")),\n",
        "           #layers.Dense(64, activation=\"relu\", name=\"layer2\"),\n",
        "           layers.Dense(3, activation=\"softmax\", name=\"output\"),\n",
        "        ]\n",
        "    )\n",
        "    \n",
        "model.summary()\n",
        "\n",
        "model.compile(\n",
        "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "        metrics=['accuracy'],\n",
        "        optimizer='adam',\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0OiFe0TQrOU"
      },
      "source": [
        "## Training\n",
        "Train the model using the training part of the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8Og1JEeR36C"
      },
      "source": [
        "history = model.fit(X_train[train_index], \n",
        "                        y_train[train_index], \n",
        "                        batch_size = 128, \n",
        "                        epochs = 100, \n",
        "                        #class_weight = class_weight, \n",
        "                        validation_data = (X_train[val_index], y_train[val_index]),\n",
        "                        #callbacks = callbacks_list,\n",
        "                        verbose = 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2X_LU55R7lI"
      },
      "source": [
        "## Evaluation\n",
        "Evaluta the model using the test part of the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mESNVUrSHgw"
      },
      "source": [
        "scores = model.evaluate(X_test, y_test, verbose=2)\n",
        "#model.save(newpath + r'\\fold-' + str(fold_no) + '.hdf5') \n",
        "#print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrsWslmzSiiO"
      },
      "source": [
        "## Cross-validation\n",
        "* Put together the building, training and evalution steps in a cross-validation loop\n",
        "* collect the mettric, e.g., accuracy, as well as the loss for each fold in a list or dictionary such that it can be processed later\n",
        "X = padded_inputs\n",
        "y = np.array(labels)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8ArZkJ-C9F5"
      },
      "source": [
        "X = padded_inputs\n",
        "y = np.array(labels)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "accuracy_per_fold = []\n",
        "loss_per_fold = []\n",
        "\n",
        "fold_no = 1\n",
        "seed = 10\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
        "\n",
        "for train_index, val_index in skf.split(X_train, y_train):\n",
        "    \n",
        "    print('Fold: ' + str(fold_no))\n",
        "    \n",
        "\n",
        "    # Define RNN model \n",
        "    model = keras.Sequential(\n",
        "        [\n",
        "           layers.Embedding(128, 64),\n",
        "           layers.Bidirectional(layers.LSTM(128, dropout = 0.4, name=\"rnn1\")),\n",
        "           #layers.Dense(64, activation=\"relu\", name=\"layer2\"),\n",
        "           layers.Dense(3, activation=\"softmax\", name=\"output\"),\n",
        "        ]\n",
        "    )\n",
        "    \n",
        "    # model.summary()\n",
        "\n",
        "    model.compile(\n",
        "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "        metrics=['accuracy'],\n",
        "        optimizer='adam',\n",
        "    )\n",
        "    \n",
        "\n",
        "    history = model.fit(X_train[train_index], \n",
        "                        y_train[train_index], \n",
        "                        batch_size = 128, \n",
        "                        epochs = 100, \n",
        "                        #class_weight = class_weight, \n",
        "                        validation_data = (X_train[val_index], y_train[val_index]),\n",
        "                        #callbacks = callbacks_list,\n",
        "                        verbose = 2)\n",
        "    \n",
        "    scores = model.evaluate(X_test, y_test, verbose=2)\n",
        "    \n",
        "    #model.save(newpath + r'\\fold-' + str(fold_no) + '.hdf5') \n",
        "\n",
        "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "    accuracy_per_fold.append(scores[1] * 100)\n",
        "    loss_per_fold.append(scores[0])\n",
        "\n",
        "    # Increase fold number\n",
        "    fold_no = fold_no + 1\n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIOJr10UDVx5"
      },
      "source": [
        "# Evaluation results\n",
        "* Print the saved evalutaion results for each of the fold as well as some statistics, like average or standard deviation\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaFouTHFDdH1"
      },
      "source": [
        "# Average scores\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(len(accuracy_per_fold)):\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {accuracy_per_fold[i]}%')\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Average scores for all folds:')\n",
        "print(f'> Accuracy: {np.mean(accuracy_per_fold)} (+- {np.std(accuracy_per_fold)})')\n",
        "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "print('------------------------------------------------------------------------')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}